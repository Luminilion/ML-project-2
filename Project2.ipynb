{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded POS data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Data sizes : (POS) 1250000 (NEG) 1250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "# Load training set\n",
    "pos = pd.read_table(data_path+'train_pos_full.txt', sep='.\\n', names=['tweet'], engine='python')\n",
    "pos['label']=1\n",
    "print(f\"Loaded POS data, correctly interpreted 1-tweet-per-line fashion : {pos.shape[0]==1_250_000}\")\n",
    "neg = pd.read_table(data_path+'train_neg_full.txt', sep='.\\n', names=['tweet'], engine='python')\n",
    "neg['label']=-1\n",
    "print(f\"Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : {neg.shape[0]==1_250_000}\")\n",
    "print(f\"Data sizes : (POS) {pos.shape[0]} (NEG) {neg.shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because your logic is so dumb , i won't even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" &lt;user&gt; just put casper in a box ! \" looved t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; thanks sir &gt; &gt; don't trip lil ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting my brother tmr is the bestest birthda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>im so sorry ! &lt;user&gt; &amp; to &lt;user&gt; &amp; &lt;user&gt; u gu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>i can't find food coloring anywhere</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>&lt;user&gt; same here ! ! but tort ! ! wonder why y...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>keyless entry remote fob clicker for 2005 buic...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>&lt;user&gt; yeap . doctor don't know what's wrong w...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "0        <user> i dunno justin read my mention or not ....      1\n",
       "1        because your logic is so dumb , i won't even c...      1\n",
       "2        \" <user> just put casper in a box ! \" looved t...      1\n",
       "3        <user> <user> thanks sir > > don't trip lil ma...      1\n",
       "4        visiting my brother tmr is the bestest birthda...      1\n",
       "...                                                    ...    ...\n",
       "2499995  im so sorry ! <user> & to <user> & <user> u gu...     -1\n",
       "2499996                i can't find food coloring anywhere     -1\n",
       "2499997  <user> same here ! ! but tort ! ! wonder why y...     -1\n",
       "2499998  keyless entry remote fob clicker for 2005 buic...     -1\n",
       "2499999  <user> yeap . doctor don't know what's wrong w...     -1\n",
       "\n",
       "[2500000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pos.merge(neg, how='outer')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both the embeddings and the vocabulary are same size :  True\n",
      "Embeddings: (101298, 20), vocab: (101298,)\n",
      "NA values were dropped in both tables: True\n",
      "Embeddings: (101296, 20), vocab: (101296,)\n"
     ]
    }
   ],
   "source": [
    "# Load word embeddings\n",
    "embeddings = np.load('embeddings.npy')\n",
    "#print(embeddings)\n",
    "\n",
    "\n",
    "# Loading vocab for verification\n",
    "words = pd.read_table('vocab_cut.txt', sep='.\\n', names=['word'], engine='python', squeeze=True, na_values=np.nan)\n",
    "\n",
    "print(f'Both the embeddings and the vocabulary are same size :  {len(embeddings)==words.shape[0]}')\n",
    "print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")\n",
    "\n",
    "# Drop NaN values\n",
    "nas = words.isna()\n",
    "words.dropna(inplace=True)\n",
    "embeddings = np.delete(embeddings, nas[nas].index.values, axis=0)\n",
    "embeddings = pd.DataFrame(embeddings)\n",
    "print(f'NA values were dropped in both tables: {len(embeddings)==words.shape[0]}')\n",
    "print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|KEY           |POS   |NEG   |\n",
      "|</cfoutput>   |     0|     1|\n",
      "|<content>     |     0|     1|\n",
      "|</popcorn>    |     1|     0|\n",
      "|<script>      |     0|     2|\n",
      "|<weirdarms>   |     1|     0|\n",
      "|<waves>       |     1|     0|\n",
      "|</body>       |     0|     1|\n",
      "|</moan>       |     0|     1|\n",
      "|<grunt>       |     1|     0|\n",
      "|<mournfully>  |     0|     1|\n",
      "|<time>        |     1|     0|\n",
      "|<impressive>  |     1|     0|\n",
      "|<c>           |     1|     2|\n",
      "|<moan>        |     0|     1|\n",
      "|<p>           |     0|    16|\n",
      "|<ages>        |     0|     1|\n",
      "|<ht>          |     0|     1|\n",
      "|<w>           |     0|     1|\n",
      "|<g>           |     1|     0|\n",
      "|<laugh>       |     1|     0|\n",
      "|<blink>       |     0|     1|\n",
      "|<calc>        |     1|     0|\n",
      "|<update>      |     0|     2|\n",
      "|<name>        |     0|     1|\n",
      "|<outstanding> |     1|     0|\n",
      "|</em>         |     0|     2|\n",
      "|<likewise>    |     1|     0|\n",
      "|</html>       |     0|     1|\n",
      "|<justkiddin>  |     0|     1|\n",
      "|<iostream>    |     0|     1|\n",
      "|<ummm>        |     0|     1|\n",
      "|</span>       |     0|     1|\n",
      "|</b>          |     1|    19|\n",
      "|<twinkle>     |     0|     1|\n",
      "|<joke>        |     1|     0|\n",
      "|<haha>        |     0|     1|\n",
      "|<strong>      |     0|     6|\n",
      "|<del>         |     0|     1|\n",
      "|<url>         | 98886|427976|\n",
      "|<emotional>   |     0|     1|\n",
      "|<retweet>     |     0|     1|\n",
      "|<weeping>     |     0|     1|\n",
      "|<gardenstuff> |     2|     0|\n",
      "|<sciencestuff>|     2|     0|\n",
      "|<ducks>       |     1|     0|\n",
      "|<thx>         |     1|     0|\n",
      "|</summary>    |     1|     0|\n",
      "|</details>    |     1|     0|\n",
      "|<please>      |     0|     1|\n",
      "|<naive>       |     0|     1|\n",
      "|<dynamic>     |     1|     0|\n",
      "|<demon>       |     0|     1|\n",
      "|<o>           |     0|     1|\n",
      "|<i>           |     0|    10|\n",
      "|<summary>     |     1|     0|\n",
      "|<user>        |1027205|578390|\n",
      "|<syrian>      |     0|     6|\n",
      "|<cutestuff>   |     2|     0|\n",
      "|</joke>       |     1|     0|\n",
      "|<mikel>       |     1|     0|\n",
      "|<parenthood>  |     0|     1|\n",
      "|<br>          |     1|     6|\n",
      "|<ducking>     |     1|     0|\n",
      "|<screams>     |     0|     1|\n",
      "|<space>       |     3|     0|\n",
      "|<attention>   |     0|     2|\n",
      "|</a>          |     1|     7|\n",
      "|<cfoutput>    |     0|     1|\n",
      "|</div>        |     0|     1|\n",
      "|<popcorn>     |     1|     0|\n",
      "|<trans>       |     0|     3|\n",
      "|<agent>       |     0|     3|\n",
      "|<hugs>        |     1|     1|\n",
      "|<atomic>      |     0|     1|\n",
      "|</i>          |     0|    11|\n",
      "|</strong>     |     0|     6|\n",
      "|<grin>        |     2|     0|\n",
      "|<hot>         |     1|     0|\n",
      "|<cont>        |     1|     0|\n",
      "|<understood>  |     1|     0|\n",
      "|<em>          |     0|     2|\n",
      "|<here>        |     1|     0|\n",
      "|<blushing>    |     1|     0|\n",
      "|<sigh>        |     0|     3|\n",
      "|<sarah>       |     1|     0|\n",
      "|</script>     |     0|     4|\n",
      "|</del>        |     0|     1|\n",
      "|<hahahahhahaha>|     0|     1|\n",
      "|<b>           |     1|    26|\n",
      "|<brr>         |     1|     0|\n",
      "|<thing>       |     0|     1|\n",
      "\n",
      "POS tweets contain 1126137 (11.88%) HTML tags.\n",
      "NEG tweets contain 1006539 (-10.62%) HTML tags.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing by \n",
    "## removing HTML tags\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# We check if the tags are relevant information between both pos and neg cases\n",
    "def count_HTML_tags(series) :\n",
    "    \"\"\"\n",
    "    Returns stats about the HTML tags in the tweet series.\n",
    "    Returns :\n",
    "    dic (defaultdict) : dict of all tags occurences.\n",
    "    count (int) : count of all tags.\"\"\"\n",
    "    dic = defaultdict(lambda:0)\n",
    "    def a(k):\n",
    "        dic[k]+=1\n",
    "        return None\n",
    "    series.apply(lambda s : [a(k) for k in re.findall('<\\/*[a-zA-Z]+>', s)])\n",
    "    count = series.str.count('<\\/*[a-zA-Z]+>').sum()\n",
    "    return dic, count\n",
    "\n",
    "# We query stats about the tags\n",
    "d_pos, n_pos = count_HTML_tags(pos['tweet'])\n",
    "d_neg, n_neg = count_HTML_tags(neg['tweet'])\n",
    "all_keys = set(d_pos.keys()) | set(d_neg.keys())\n",
    "\n",
    "print(f\"|{'KEY':14s}|{'POS':6s}|{'NEG':6s}|\")\n",
    "for k in all_keys : \n",
    "    print(f\"|{k:14s}|{d_pos[k]:6d}|{d_neg[k]:6d}|\")\n",
    "\n",
    "print(f\"\\nPOS tweets contain {n_pos} ({(n_pos-n_neg)*100/n_neg:.2f}%) HTML tags.\")\n",
    "print(f\"NEG tweets contain {n_neg} ({(n_neg-n_pos)*100/n_pos:.2f}%) HTML tags.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Although the difference in number of tags is not significant. The distribution of them is quite significant (i.e. for tags `<url>` and `<user>`). Thus we choose to leave the tags as part of the tweet. **THIS COULD BE REVIEWED TO IMPROVE PERF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the HTML tags from the tweets\n",
    "## CHANGE RETURN VAR IF RELEVANT\n",
    "\n",
    "def clean_HTML_tags(series) :\n",
    "    return series.str.replace('<\\/*[a-zA-Z]+>', '', regex=True)\n",
    "\n",
    "t = clean_HTML_tags(pos['tweet'])\n",
    "t2 = clean_HTML_tags(neg['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(tweet):\n",
    "    split_by_words = tweet.split()\n",
    "    embed_list = []\n",
    "    for i in range(len(split_by_words)):\n",
    "        try:\n",
    "            embed_list.append(  embeddings.loc[vocab.loc[split_by_words[i]][0]].values  )\n",
    "        except Exception:\n",
    "            pass\n",
    "    mean = np.zeros(20) if not embed_list else np.mean(embed_list, axis=0) \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only 10'000 samples for faster computation\n",
    "from sklearn.utils import resample\n",
    "pos_ = resample(pos, n_samples=10000, replace=False)\n",
    "neg_ = resample(neg, n_samples=10000, replace=False)\n",
    "tweets_ = pos_.merge(neg_, how='outer')\n",
    "tweets_['mean_embed']= tweets_['tweet'].map(compute_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To format the testing data\n",
    "def extract_tweet(tweet):\n",
    "    return tweet.split(\",\", 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>had a nice time w / my friend lastnite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>&lt;user&gt; no it's not ! please stop !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>not without my daughter ( dvd two-time oscar (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>&lt;user&gt; have fun in class sweetcheeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>making a r . e . a . l . difference . ( get r ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet\n",
       "1      sea doo pro sea scooter ( sports with the port...\n",
       "2      <user> shucks well i work all week so now i ca...\n",
       "3                i cant stay away from bug thats my baby\n",
       "4      <user> no ma'am ! ! ! lol im perfectly fine an...\n",
       "5      whenever i fall asleep watching the tv , i alw...\n",
       "...                                                  ...\n",
       "9996              had a nice time w / my friend lastnite\n",
       "9997                  <user> no it's not ! please stop !\n",
       "9998   not without my daughter ( dvd two-time oscar (...\n",
       "9999                <user> have fun in class sweetcheeks\n",
       "10000  making a r . e . a . l . difference . ( get r ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the testing data\n",
    "test = pd.read_fwf(data_path+ 'test_data.txt', sep=\"\\n\", header=None)\n",
    "test.index = pd.RangeIndex(start=1, stop=10001, step=1)\n",
    "test = test[0].map(extract_tweet)\n",
    "test = pd.DataFrame(test)\n",
    "test.columns = ['tweet']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "X = tweets_['mean_embed'].values\n",
    "y = tweets_['label'].values\n",
    "X=X.tolist()\n",
    "y=y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "test['mean_embed']= test['tweet'].map(compute_mean)\n",
    "test['label'] = clf.predict(test['mean_embed'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating submission file\n",
    "import csv\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})\n",
    "            \n",
    "create_csv_submission(test.index, test['label'].values, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
