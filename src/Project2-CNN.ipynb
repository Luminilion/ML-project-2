{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Generic Functions\n",
    "Here we define all the functions to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, pos_file, neg_file, size=1_250_000): \n",
    "\n",
    "    # positive\n",
    "    pos = pd.read_table(data_path+pos_file, sep='.\\n', names=['tweet'], engine='python')\n",
    "    pos['label']=1\n",
    "    print(f\"Loaded POS data, correctly interpreted 1-tweet-per-line fashion : {pos.shape[0]==size}\")\n",
    "\n",
    "    # negative\n",
    "    neg = pd.read_table(data_path+neg_file, sep='.\\n', names=['tweet'], engine='python')\n",
    "    neg['label']=-1\n",
    "    print(f\"Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : {neg.shape[0]==size}\")\n",
    "\n",
    "    # Data sizes\n",
    "    print(f\"Number of tweets : (POS) {pos.shape[0]} (NEG) {neg.shape[0]}\\n\")\n",
    "\n",
    "    # Merge datasets to get a complete training set\n",
    "    tweets = pos.append(neg)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove_helper import concatenate\n",
    "\n",
    "def load_embeddings_and_vocab(embeddings_loc, embeddings_path, vocab_loc, divided=False) :\n",
    "    \n",
    "    ## Load word embeddings and vocabulary to compute word vectors of tweets -----------------------------------\n",
    "    \n",
    "    # Load word embeddings\n",
    "    embeddings=None\n",
    "    if divided : \n",
    "        embeddings = concatenate(embeddings_files, embeddings_path)\n",
    "    else :\n",
    "        embeddings = np.load(embeddings_path+embeddings_loc)\n",
    "    print(f'Loaded word embeddings in structure of type {type(embeddings)}.')\n",
    "\n",
    "    # Loading vocab\n",
    "    words = pd.read_table(vocab_loc, sep='.\\n', names=['word'], engine='python', squeeze=True, na_values=np.nan)\n",
    "    print(f'Loaded word vocabulary in structure of type {type(words)}.')\n",
    "\n",
    "    # Check that the vocabulary encompasses all embedded words\n",
    "    print(f'\\nBoth the embeddings and the vocabulary are same length :  {len(embeddings)==words.shape[0]}')\n",
    "    print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")\n",
    "\n",
    "    ## Clean the data --------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Drop NaN values in vocab\n",
    "    nas = words.isna()\n",
    "    words.dropna(inplace=True)\n",
    "    # Drop NaN words in embeddings\n",
    "    embeddings = np.delete(embeddings, nas[nas].index.values, axis=0)\n",
    "    \n",
    "    print(f'NaN values were dropped in both tables: {len(embeddings)==words.shape[0]}')\n",
    "    print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")\n",
    "\n",
    "    ## Process data ---------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Index by words for faster index-for-word search\n",
    "    words = pd.DataFrame(data=words.index, index=words.values)\n",
    "    embeddings = pd.DataFrame(embeddings, index=words.index)\n",
    "    \n",
    "    return embeddings, words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def resample_data(data, size, label=1, seed=None) :\n",
    "    # Get pos and neg datasets\n",
    "    pos, neg = data.loc[data['label']==label], data.loc[data['label']!=label]\n",
    "    \n",
    "    # Get samples balanced by classes\n",
    "    n = int(size/2)\n",
    "    pos_ = resample(pos, n_samples=n, replace=False, random_state=seed)\n",
    "    neg_ = resample(neg, n_samples=n, replace=False, random_state=seed)\n",
    "    \n",
    "    # reform dataset\n",
    "    data_ = pos_.append(neg_)\n",
    "\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tweet, embeddings, embeddings_dim, vocab, agg_func=None):\n",
    "    \"\"\"\n",
    "    Creates the feature vector corresponding to the tweet.\n",
    "    To do so, computes the mean of the word embeddings corresponding to the vocabulary words in the tweet.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    tweet : str\n",
    "        Input tweet from which the word vector is created.\n",
    "    \"\"\"\n",
    "    split_by_words = tweet.split()\n",
    "    embed_list = []\n",
    "    \n",
    "    # Get words in tweet that are in vocab\n",
    "    # Get embeddings for these words\n",
    "    for w in split_by_words:\n",
    "        if w in vocab.index :\n",
    "            embed_list.append(  embeddings.loc[w].values  )\n",
    "            \n",
    "    if agg_func is None :\n",
    "        agg_func = lambda x : np.mean(x, axis=0)\n",
    "    \n",
    "    # If no vocab word create an empty vector for the tweet\n",
    "    if not embed_list :\n",
    "        embed_list = np.zeros((2, embeddings_dim))\n",
    "        \n",
    "    result = agg_func(embed_list)\n",
    "    \n",
    "    # Be sure to output a list to store in dataframe\n",
    "    return np.array(result).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove_helper import concatenate\n",
    "\n",
    "def load_word_vectors(file_path, file_loc, divided=False): \n",
    "    # Load pre-computed word vectors file\n",
    "    precomputed = None\n",
    "    if divided :\n",
    "        print('Loading from divided dataset...')\n",
    "        precomputed = concatenate(word_vectors_files, file_path)\n",
    "    else : \n",
    "        precomputed = np.load(file_path+file_loc, allow_pickle=True)\n",
    "        \n",
    "    precomputed = pd.DataFrame(precomputed, columns=['index', 'label', 'mean_embed'])\n",
    "    print('Successfully loaded from file!')\n",
    "    \n",
    "    return precomputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project2_helper import isAdmin, parallelize\n",
    "\n",
    "def compute_word_vectors(data, embeddings, embeddings_dim, vocab, agg_func=None) :\n",
    "    data = data.copy()\n",
    "    \n",
    "    # compute function to run on tweets\n",
    "    func = lambda t : word_vector(t, embeddings, embeddings_dim, vocab, agg_func=agg_func)\n",
    "    \n",
    "    if isAdmin():\n",
    "        print('Process is run as admin. Running parallelized computation...')\n",
    "        data['mean_embed']= parallelize(data['tweet'], func)\n",
    "    else : \n",
    "        print('Process is not run as admin. Cannot run parallelized setting, running as sequential...')\n",
    "        data['mean_embed']= data['tweet'].map(func)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_vectors(data, file_path, ending=None):\n",
    "    \n",
    "    # Get word vectors information\n",
    "    word_vectors = data[['label', 'mean_embed']].reset_index()\n",
    "    dim = len(word_vectors.loc[0, 'mean_embed'])\n",
    "    \n",
    "    # Name file to format : path/word_vectors_xxnsamplesxx_xxembeddimxx_ending_npy\n",
    "    name = file_path + 'word_vectors_' + str(data.shape[0]) + '_' + str(dim)\n",
    "    # Add ending if requested\n",
    "    if ending is not None :\n",
    "        name = name+'_'+str(ending)\n",
    "    \n",
    "    # save data\n",
    "    np.save(name, word_vectors)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(data, test_size=0.25, seed=None) : \n",
    "\n",
    "    # Split into training and testing data\n",
    "    train, test = train_test_split(data, test_size=test_size, random_state=seed)\n",
    "    print(f\"Local training set size : {train.shape[0]}.\")\n",
    "    print(f\"Local testing set size : {test.shape[0]}.\\n\")\n",
    "     \n",
    "    # Create features and labels datasets\n",
    "    xtrain, ytrain = np.array(train.mean_embed.tolist()), np.array(train.label.to_list())\n",
    "    xtest, ytest = np.array(test.mean_embed.tolist()), np.array(test.label.tolist())\n",
    "\n",
    "    print(f'Training sample shape: {xtrain.shape[1:]}')\n",
    "    print(f'Testing sample shape: {xtest.shape[1:]}')\n",
    "    \n",
    "    return xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "def preprocess(X) :\n",
    "    x=X.copy()\n",
    "    \n",
    "    ## Standardize data\n",
    "    # If features are list of features of different sizes, standardization has to be made list-wise\n",
    "    if len(np.array(x).shape) == 1 : \n",
    "        x = np.array([ StandardScaler().fit_transform(a) for a in x ])\n",
    "    else :\n",
    "        x = StandardScaler().fit_transform(x)\n",
    "    \n",
    "    ## TODO Polynomial features and interactions\n",
    "    \n",
    "    ## other data preprocessing\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To format the testing data\n",
    "def extract_tweet(tweet):\n",
    "    return tweet.split(\",\", 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(data_path, test_file='test_data.txt') :\n",
    "    # Load the testing data\n",
    "    test = pd.read_fwf(data_path+test_file, sep=\"\\n\", header=None)\n",
    "    test = test.rename(columns={0:'tweet', 1:'na1', 2:'na2'})\n",
    "\n",
    "    # Reformating it for submission\n",
    "    test.index = test.index+1 # Format asked by AI Crowd\n",
    "    test = test['tweet'].map(extract_tweet).to_frame()\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating submission file\n",
    "import csv\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base parameters\n",
    "\n",
    "### Loading\n",
    "data_path = '../data/'\n",
    "pos_data = 'train_pos_full.txt'\n",
    "neg_data = 'train_neg_full.txt'\n",
    "\n",
    "precomputed_path = '../precomputed_data/'\n",
    "embeddings_file = 'embeddings_full_10epoch_100dim.npy'\n",
    "vocab_loc = '../data/vocab_cut.txt'\n",
    "\n",
    "embeddings_dim_info = 100\n",
    "data_size = 100_000\n",
    "\n",
    "word_vectors_files = ['word_vectors_100000_100_part1.npy',\n",
    "                     'word_vectors_100000_100_part2.npy']\n",
    "divided_word_vectors = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded POS data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Number of tweets : (POS) 1250000 (NEG) 1250000\n",
      "\n",
      "Loaded word embeddings in structure of type <class 'numpy.ndarray'>.\n",
      "Loaded word vocabulary in structure of type <class 'pandas.core.series.Series'>.\n",
      "\n",
      "Both the embeddings and the vocabulary are same length :  True\n",
      "Embeddings: (101298, 100), vocab: (101298,)\n",
      "NaN values were dropped in both tables: True\n",
      "Embeddings: (101296, 100), vocab: (101296,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "tweets = load_data(data_path, pos_data, neg_data)\n",
    "embeddings, vocab = load_embeddings_and_vocab(embeddings_file, precomputed_path, vocab_loc)\n",
    "\n",
    "# Resample data\n",
    "tweets_ = resample_data(tweets, data_size, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from divided dataset...\n",
      "Successfully loaded from file!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load word vectors\n",
    "tweets_ = load_word_vectors(\n",
    "    precomputed_path, \n",
    "    word_vectors_files, \n",
    "    divided=divided_word_vectors)\n",
    "\n",
    "# Useless here (for demonstration purposes in case of computation and not loading)\n",
    "save_word_vectors(tweets_, precomputed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local training set size : 75000.\n",
      "Local testing set size : 25000.\n",
      "\n",
      "Training sample shape: (100,)\n",
      "Testing sample shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split data\n",
    "xtrain_, ytrain_, xtest_, ytest_ = split_dataset(tweets_)\n",
    "\n",
    "# Pre-process training set\n",
    "xtrain_ = preprocess(xtrain_)\n",
    "xtest_ = preprocess(xtest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing functions to estimate model efficiency\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Training\n",
    "* Linear Regression\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Neural Network classifier is 0.60532.\n",
      "Wall time: 3min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#### BASELINE : Neural Networks\n",
    "\n",
    "# Neural Network\n",
    "name = 'Neural Network'\n",
    "\n",
    "nn_classifier = MLPClassifier().fit(xtrain_,ytrain_)\n",
    "score = nn_classifier.score(xtest_,ytest_)\n",
    "\n",
    "classifiers[name] = (nn_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} classifier is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos    0.59925   0.66659   0.63113     12663\n",
      "         neg    0.61316   0.54243   0.57563     12337\n",
      "\n",
      "    accuracy                        0.60532     25000\n",
      "   macro avg    0.60620   0.60451   0.60338     25000\n",
      "weighted avg    0.60611   0.60532   0.60374     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predtest_ = nn_classifier.predict(xtest_)\n",
    "\n",
    "metrics = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5, output_dict=True)\n",
    "report = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save baseline results\n",
    "path = '../results/'\n",
    "name = path+'metrics_'+str(local_t_size)+'_'+str(embeddings_dim_info)+'_baseline'\n",
    "np.save(name, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Custom models\n",
    "Let us implement a custom model following the paper $\\text{Text Classification with Deep Neural Networks}$ by *Maaz Amajd et al.* from Microsoft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base parameters\n",
    "\n",
    "### Loading\n",
    "data_path = '../data/'\n",
    "pos_data = 'train_pos_full.txt'\n",
    "neg_data = 'train_neg_full.txt'\n",
    "\n",
    "precomputed_path = '../precomputed_data/'\n",
    "embeddings_file = 'embeddings_full_10epoch_100dim.npy'\n",
    "vocab_loc = '../data/vocab_cut.txt'\n",
    "\n",
    "embeddings_dim_info = 100\n",
    "data_size = 100_000\n",
    "\n",
    "word_vectors_file = 'word_vectors_100000_12_cnn.npy'\n",
    "divided_word_vectors = True\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recompute word vectors datasets\n",
    "The convolutionnal Neural Network uses a matrix as input format. Here we use a matrix of words vectors representing the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded from file!\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Resample tweets for cnn\n",
    "tweets_cnn = resample_data(tweets, data_size, seed=seed)\n",
    "\n",
    "# Compute matrices of word embeddings for tweets\n",
    "#tweets_cnn = compute_word_vectors(tweets_cnn, embeddings, embeddings_dim_info, vocab, agg_func=(lambda _ : _))\n",
    "tweets_cnn = load_word_vectors(precomputed_path, word_vectors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save computed word embeddings matrices \n",
    "save_word_vectors(tweets_cnn, precomputed_path, ending='cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local training set size : 75000.\n",
      "Local testing set size : 25000.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-288999fe21b1>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  xtrain, ytrain = np.array(train.mean_embed.tolist()), np.array(train.label.to_list())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample shape: ()\n",
      "Testing sample shape: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-288999fe21b1>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  xtest, ytest = np.array(test.mean_embed.tolist()), np.array(test.label.tolist())\n"
     ]
    }
   ],
   "source": [
    "# Train test split data\n",
    "xtrain_cnn, ytrain_cnn, xtest_cnn, ytest_cnn = split_dataset(tweets_cnn, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-415d7496b1fe>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x = np.array([ StandardScaler().fit_transform(a) for a in x ])\n",
      "<ipython-input-10-415d7496b1fe>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x = np.array([ StandardScaler().fit_transform(a) for a in x ])\n"
     ]
    }
   ],
   "source": [
    "# Preprocess datasets\n",
    "xtrain_cnn = preprocess(xtrain_cnn)\n",
    "xtest_cnn = preprocess(xtest_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tweet_matrices(tweets, embed_dim, words_per_tweet) : \n",
    "    # may have to change shape to (w, e, 1)\n",
    "    result = [np.resize(t, (words_per_tweet, embed_dim)).tolist() for t in tweets]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cnn = reshape_tweet_matrices(xtrain_cnn, embeddings_dim_info, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cnn = np.array(xtrain_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# Define base parameters for the CNN\n",
    "\n",
    "batch_size = 64 ## TODO tune batch size (depends on mem)\n",
    "epochs = 20\n",
    "num_classes = 2\n",
    "n_filters = 100\n",
    "kernel_size = (3, 3)\n",
    "dense_units = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 15, 100, 100)      1000      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 15, 100, 100)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 50, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 250)               10000250  \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 10,001,752\n",
      "Trainable params: 10,001,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the layers of the CNN\n",
    "cnn_classifier = Sequential()\n",
    "cnn_classifier.add(Conv2D(n_filters, kernel_size=kernel_size, activation='relu',input_shape=(15, embeddings_dim_info, 1), padding='same'))\n",
    "cnn_classifier.add(LeakyReLU(alpha=0.1))\n",
    "cnn_classifier.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "cnn_classifier.add(Flatten())\n",
    "cnn_classifier.add(Dense(dense_units, activation='relu'))\n",
    "#cnn_classifier.add(LeakyReLU(alpha=0.1))                  \n",
    "cnn_classifier.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "cnn_classifier.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "cnn_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_cnn.resize((75000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "ytrain_cnn = np.array([ 0 if x==-1 else x for x in ytrain_cnn ])\n",
    "ytrain_cnn = to_categorical(ytrain_cnn)\n",
    "ytrain_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "cnn_history = cnn_classifier.fit(xtrain_cnn, ytrain_cnn, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test data\n",
    "xtest_cnn = reshape_tweet_matrices(xtest_cnn, embeddings_dim_info, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 15, 100, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_cnn = np.array(xtest_cnn)\n",
    "xtest_cnn.resize((25000, 15, 100, 1))\n",
    "xtest_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_cnn = np.array([ 0 if x==-1 else x for x in ytest_cnn ])\n",
    "ytest_cnn = to_categorical(ytest_cnn)\n",
    "ytest_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 19s 24ms/step - loss: 1.6181 - accuracy: 0.6066\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "test_eval = cnn_classifier.evaluate(xtest_cnn, ytest_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6181174516677856, 0.6065999865531921]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernelsize 3, batchsize 32, filtersize=100\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 15, 100, 100)      1000      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 50, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 250)               10000250  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 10,001,752\n",
      "Trainable params: 10,001,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 269s 144ms/step - loss: 0.6758 - accuracy: 0.5847 - val_loss: 0.6564 - val_accuracy: 0.6025\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 210s 112ms/step - loss: 0.6404 - accuracy: 0.6171 - val_loss: 0.6611 - val_accuracy: 0.5933\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 205s 109ms/step - loss: 0.6188 - accuracy: 0.6377 - val_loss: 0.6427 - val_accuracy: 0.6133\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 190s 101ms/step - loss: 0.5947 - accuracy: 0.6611 - val_loss: 0.6434 - val_accuracy: 0.6225\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 190s 101ms/step - loss: 0.5625 - accuracy: 0.6919 - val_loss: 0.6665 - val_accuracy: 0.6165\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 190s 101ms/step - loss: 0.5190 - accuracy: 0.7243 - val_loss: 0.6972 - val_accuracy: 0.6094\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 190s 101ms/step - loss: 0.4657 - accuracy: 0.7628 - val_loss: 0.7751 - val_accuracy: 0.6006\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 191s 102ms/step - loss: 0.4074 - accuracy: 0.7971 - val_loss: 0.8437 - val_accuracy: 0.6078\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 188s 100ms/step - loss: 0.3498 - accuracy: 0.8319 - val_loss: 0.9419 - val_accuracy: 0.6095\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.2963 - accuracy: 0.8605 - val_loss: 1.1393 - val_accuracy: 0.6010\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.2566 - accuracy: 0.8823 - val_loss: 1.2700 - val_accuracy: 0.6015\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.2224 - accuracy: 0.9002 - val_loss: 1.4577 - val_accuracy: 0.6085\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.1971 - accuracy: 0.9120 - val_loss: 1.5937 - val_accuracy: 0.6051\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 190s 101ms/step - loss: 0.1758 - accuracy: 0.9216 - val_loss: 1.7266 - val_accuracy: 0.6059\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.1620 - accuracy: 0.9296 - val_loss: 1.9144 - val_accuracy: 0.6044\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.1406 - accuracy: 0.9390 - val_loss: 2.0455 - val_accuracy: 0.5965\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 188s 101ms/step - loss: 0.1369 - accuracy: 0.9439 - val_loss: 1.9771 - val_accuracy: 0.5991\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 188s 101ms/step - loss: 0.1194 - accuracy: 0.9507 - val_loss: 2.2338 - val_accuracy: 0.5973\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 188s 100ms/step - loss: 0.1173 - accuracy: 0.9521 - val_loss: 2.3048 - val_accuracy: 0.6032\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 192s 102ms/step - loss: 0.1000 - accuracy: 0.9605 - val_loss: 2.6486 - val_accuracy: 0.5997\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 2.7759 - accuracy: 0.5945\n",
      "kernelsize 3, batchsize 32, filtersize=200\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 15, 100, 200)      2000      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 50, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 80000)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 250)               20000250  \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 20,002,752\n",
      "Trainable params: 20,002,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.6826 - accuracy: 0.5853 - val_loss: 0.6546 - val_accuracy: 0.6123\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.6399 - accuracy: 0.6158 - val_loss: 0.6492 - val_accuracy: 0.5973\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 361s 193ms/step - loss: 0.6155 - accuracy: 0.6406 - val_loss: 0.6472 - val_accuracy: 0.6042\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.5854 - accuracy: 0.6716 - val_loss: 0.6513 - val_accuracy: 0.6067\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 362s 193ms/step - loss: 0.5397 - accuracy: 0.7115 - val_loss: 0.6912 - val_accuracy: 0.6078\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 361s 192ms/step - loss: 0.4816 - accuracy: 0.7544 - val_loss: 0.7490 - val_accuracy: 0.5996\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.4098 - accuracy: 0.8031 - val_loss: 0.8285 - val_accuracy: 0.6029\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 361s 193ms/step - loss: 0.3339 - accuracy: 0.8449 - val_loss: 0.9665 - val_accuracy: 0.5986\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 361s 192ms/step - loss: 0.2658 - accuracy: 0.8818 - val_loss: 1.2001 - val_accuracy: 0.5999\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.2152 - accuracy: 0.9079 - val_loss: 1.3233 - val_accuracy: 0.5929\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 360s 192ms/step - loss: 0.1746 - accuracy: 0.9278 - val_loss: 1.5998 - val_accuracy: 0.5970\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 365s 195ms/step - loss: 0.1481 - accuracy: 0.9419 - val_loss: 1.7900 - val_accuracy: 0.5979\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 373s 199ms/step - loss: 0.1264 - accuracy: 0.9518 - val_loss: 1.9337 - val_accuracy: 0.6003\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.1103 - accuracy: 0.9584 - val_loss: 2.0149 - val_accuracy: 0.5923\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 363s 194ms/step - loss: 0.0961 - accuracy: 0.9658 - val_loss: 2.2997 - val_accuracy: 0.6018\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 362s 193ms/step - loss: 0.0913 - accuracy: 0.9684 - val_loss: 2.3978 - val_accuracy: 0.5988\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.0832 - accuracy: 0.9717 - val_loss: 2.5644 - val_accuracy: 0.5939\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 362s 193ms/step - loss: 0.0713 - accuracy: 0.9754 - val_loss: 2.6457 - val_accuracy: 0.5946\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 363s 194ms/step - loss: 0.0710 - accuracy: 0.9764 - val_loss: 2.7157 - val_accuracy: 0.5983\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 364s 194ms/step - loss: 0.0684 - accuracy: 0.9767 - val_loss: 2.6926 - val_accuracy: 0.5994\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 2.6321 - accuracy: 0.6054\n",
      "kernelsize 3, batchsize 32, filtersize=300\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 15, 100, 300)      3000      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 50, 300)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 120000)            0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 250)               30000250  \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 30,003,752\n",
      "Trainable params: 30,003,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 576s 307ms/step - loss: 0.6807 - accuracy: 0.5881 - val_loss: 0.6473 - val_accuracy: 0.6063\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 547s 292ms/step - loss: 0.6361 - accuracy: 0.6185 - val_loss: 0.6409 - val_accuracy: 0.6153\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 541s 288ms/step - loss: 0.6109 - accuracy: 0.6451 - val_loss: 0.6383 - val_accuracy: 0.6127\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 540s 288ms/step - loss: 0.5773 - accuracy: 0.6803 - val_loss: 0.7003 - val_accuracy: 0.6086\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 542s 289ms/step - loss: 0.5308 - accuracy: 0.7191 - val_loss: 0.6868 - val_accuracy: 0.6083\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 539s 288ms/step - loss: 0.4697 - accuracy: 0.7619 - val_loss: 0.7557 - val_accuracy: 0.5987\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 542s 289ms/step - loss: 0.3995 - accuracy: 0.8076 - val_loss: 0.8402 - val_accuracy: 0.5945\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 540s 288ms/step - loss: 0.3247 - accuracy: 0.8490 - val_loss: 0.9648 - val_accuracy: 0.5909\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 539s 287ms/step - loss: 0.2659 - accuracy: 0.8818 - val_loss: 1.1632 - val_accuracy: 0.5861\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 539s 287ms/step - loss: 0.2154 - accuracy: 0.9078 - val_loss: 1.3648 - val_accuracy: 0.5967\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 541s 288ms/step - loss: 0.1802 - accuracy: 0.9253 - val_loss: 1.6299 - val_accuracy: 0.5955\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 540s 288ms/step - loss: 0.1532 - accuracy: 0.9384 - val_loss: 1.7854 - val_accuracy: 0.5983\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 541s 288ms/step - loss: 0.1328 - accuracy: 0.9479 - val_loss: 1.9110 - val_accuracy: 0.5913\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 539s 287ms/step - loss: 0.1205 - accuracy: 0.9538 - val_loss: 1.9894 - val_accuracy: 0.5905\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 541s 288ms/step - loss: 0.1069 - accuracy: 0.9608 - val_loss: 2.2137 - val_accuracy: 0.5914\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 539s 288ms/step - loss: 0.0989 - accuracy: 0.9651 - val_loss: 2.4097 - val_accuracy: 0.5957\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 538s 287ms/step - loss: 0.0865 - accuracy: 0.9690 - val_loss: 2.4512 - val_accuracy: 0.5991\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 539s 287ms/step - loss: 0.0802 - accuracy: 0.9726 - val_loss: 2.4986 - val_accuracy: 0.5936\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 538s 287ms/step - loss: 0.0711 - accuracy: 0.9759 - val_loss: 2.7591 - val_accuracy: 0.5966\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 538s 287ms/step - loss: 0.0707 - accuracy: 0.9760 - val_loss: 2.7917 - val_accuracy: 0.5831\n",
      "782/782 [==============================] - 52s 66ms/step - loss: 2.7995 - accuracy: 0.5884\n",
      "kernelsize 3, batchsize 64, filtersize=100\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 15, 100, 100)      1000      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 50, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 250)               10000250  \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 10,001,752\n",
      "Trainable params: 10,001,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 133s 141ms/step - loss: 0.6970 - accuracy: 0.5803 - val_loss: 0.6521 - val_accuracy: 0.6063\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 134s 142ms/step - loss: 0.6439 - accuracy: 0.6140 - val_loss: 0.6477 - val_accuracy: 0.6097\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 136s 145ms/step - loss: 0.6312 - accuracy: 0.6237 - val_loss: 0.6419 - val_accuracy: 0.6114\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 134s 143ms/step - loss: 0.6180 - accuracy: 0.6296 - val_loss: 0.6443 - val_accuracy: 0.6137\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 133s 142ms/step - loss: 0.6063 - accuracy: 0.6375 - val_loss: 0.6560 - val_accuracy: 0.6102\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 133s 142ms/step - loss: 0.5929 - accuracy: 0.6430 - val_loss: 0.6515 - val_accuracy: 0.6052\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 134s 143ms/step - loss: 0.5786 - accuracy: 0.6640 - val_loss: 0.6560 - val_accuracy: 0.6024\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 135s 144ms/step - loss: 0.5673 - accuracy: 0.6693 - val_loss: 0.6603 - val_accuracy: 0.5851\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 133s 142ms/step - loss: 0.5544 - accuracy: 0.6814 - val_loss: 0.6776 - val_accuracy: 0.5534\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 133s 141ms/step - loss: 0.5429 - accuracy: 0.6894 - val_loss: 0.6734 - val_accuracy: 0.5905\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 133s 142ms/step - loss: 0.5323 - accuracy: 0.6952 - val_loss: 0.7019 - val_accuracy: 0.5937\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 132s 141ms/step - loss: 0.5197 - accuracy: 0.7064 - val_loss: 0.7238 - val_accuracy: 0.5913\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 133s 142ms/step - loss: 0.5113 - accuracy: 0.7112 - val_loss: 0.7328 - val_accuracy: 0.5873\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 132s 141ms/step - loss: 0.4983 - accuracy: 0.7179 - val_loss: 0.7090 - val_accuracy: 0.5798\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 133s 141ms/step - loss: 0.4891 - accuracy: 0.7258 - val_loss: 0.7544 - val_accuracy: 0.5900\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 133s 141ms/step - loss: 0.4778 - accuracy: 0.7323 - val_loss: 0.8251 - val_accuracy: 0.5745\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 134s 143ms/step - loss: 0.4677 - accuracy: 0.7380 - val_loss: 0.8455 - val_accuracy: 0.5937\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 133s 141ms/step - loss: 0.4587 - accuracy: 0.7435 - val_loss: 0.9105 - val_accuracy: 0.5905\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 132s 141ms/step - loss: 0.4515 - accuracy: 0.7495 - val_loss: 0.9145 - val_accuracy: 0.5993\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 134s 142ms/step - loss: 0.4401 - accuracy: 0.7541 - val_loss: 0.9124 - val_accuracy: 0.5891\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.9033 - accuracy: 0.5948\n",
      "kernelsize 3, batchsize 64, filtersize=200\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 15, 100, 200)      2000      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 50, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 80000)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 250)               20000250  \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 20,002,752\n",
      "Trainable params: 20,002,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 258s 276ms/step - loss: 0.7158 - accuracy: 0.5815 - val_loss: 0.6614 - val_accuracy: 0.5847\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 257s 274ms/step - loss: 0.6457 - accuracy: 0.6115 - val_loss: 0.6465 - val_accuracy: 0.6051\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 259s 276ms/step - loss: 0.6254 - accuracy: 0.6341 - val_loss: 0.6405 - val_accuracy: 0.6193\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 258s 275ms/step - loss: 0.6052 - accuracy: 0.6536 - val_loss: 0.6434 - val_accuracy: 0.6169\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 259s 276ms/step - loss: 0.5794 - accuracy: 0.6786 - val_loss: 0.6584 - val_accuracy: 0.6118\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 256s 273ms/step - loss: 0.5497 - accuracy: 0.7052 - val_loss: 0.6733 - val_accuracy: 0.6126\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 256s 273ms/step - loss: 0.5113 - accuracy: 0.7341 - val_loss: 0.6979 - val_accuracy: 0.6110\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 276s 294ms/step - loss: 0.4628 - accuracy: 0.7707 - val_loss: 0.7296 - val_accuracy: 0.6066\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 276s 295ms/step - loss: 0.4079 - accuracy: 0.8043 - val_loss: 0.8247 - val_accuracy: 0.6017\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 277s 295ms/step - loss: 0.3502 - accuracy: 0.8384 - val_loss: 0.9507 - val_accuracy: 0.6011\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 276s 294ms/step - loss: 0.2997 - accuracy: 0.8661 - val_loss: 1.1565 - val_accuracy: 0.6061\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 277s 295ms/step - loss: 0.2536 - accuracy: 0.8904 - val_loss: 1.2221 - val_accuracy: 0.5989\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 284s 302ms/step - loss: 0.2117 - accuracy: 0.9105 - val_loss: 1.3331 - val_accuracy: 0.5955\n",
      "Epoch 14/20\n",
      "161/938 [====>.........................] - ETA: 3:57 - loss: 0.1530 - accuracy: 0.9428"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "num_classes = 2\n",
    "dense_units = 250\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for ks in [3,4,5] :\n",
    "    for bs in [32,64,128] :\n",
    "        for fs in [100, 200, 300] :\n",
    "            print(f\"kernelsize {ks}, batchsize {bs}, filtersize={fs}\")\n",
    "            \n",
    "            # Create the layers of the CNN\n",
    "            cnn_classifier = Sequential()\n",
    "            cnn_classifier.add(Conv2D(fs, kernel_size=(ks,ks), activation='relu',input_shape=(15, embeddings_dim_info, 1), padding='same'))\n",
    "            #cnn_classifier.add(LeakyReLU(alpha=0.1))\n",
    "            cnn_classifier.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "            cnn_classifier.add(Flatten())\n",
    "            cnn_classifier.add(Dense(dense_units, activation='relu'))\n",
    "            #cnn_classifier.add(LeakyReLU(alpha=0.1))                  \n",
    "            cnn_classifier.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "            cnn_classifier.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "            print(cnn_classifier.summary())\n",
    "\n",
    "            # Train the model\n",
    "            cnn_history = cnn_classifier.fit(xtrain_cnn, ytrain_cnn, batch_size=bs,epochs=epochs,verbose=1, validation_split=0.2)\n",
    "\n",
    "            # Evaluate Model\n",
    "            test_eval = cnn_classifier.evaluate(xtest_cnn, ytest_cnn)\n",
    "            \n",
    "            results[(ks,bs,fs)] = (cnn_history, test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNN results\n",
    "path = '../results/'\n",
    "name = path+'metrics_'+str(local_t_size)+'_'+str(embeddings_dim_info)+'_CNN'\n",
    "np.save(name, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing\n",
    "This section is dedicated to using the previous classifiers to predict the labels of the provided testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1193381</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.032002123948292126, -0.014642657203437489, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>644929</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.10238272539678156, -0.02736877932503185, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>578303</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.032941437860502285, 0.0014634508830161917, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>525309</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04879550502681794, 0.017707842326910788, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34941</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1420258276670681, -0.03843481256309387, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1159713</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.15079636217861106, 0.005626630631020118, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>249113</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.05451928253254213, -0.052474023026710545, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>913236</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.09112505455684311, 0.040824608634503316, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>830941</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.12102069953544096, -0.047875157832210066, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>34871</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.12092917762249158, -0.06853298903401578, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index label                                         mean_embed\n",
       "0      1193381     1  [0.032002123948292126, -0.014642657203437489, ...\n",
       "1       644929     1  [0.10238272539678156, -0.02736877932503185, 0....\n",
       "2       578303     1  [0.032941437860502285, 0.0014634508830161917, ...\n",
       "3       525309     1  [0.04879550502681794, 0.017707842326910788, 0....\n",
       "4        34941     1  [0.1420258276670681, -0.03843481256309387, 0.0...\n",
       "...        ...   ...                                                ...\n",
       "99995  1159713    -1  [0.15079636217861106, 0.005626630631020118, 0....\n",
       "99996   249113    -1  [0.05451928253254213, -0.052474023026710545, 0...\n",
       "99997   913236    -1  [0.09112505455684311, 0.040824608634503316, 0....\n",
       "99998   830941    -1  [0.12102069953544096, -0.047875157832210066, 0...\n",
       "99999    34871    -1  [0.12092917762249158, -0.06853298903401578, 0....\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is not run as admin. Cannot run parallelized setting, running as sequential...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-415d7496b1fe>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if len(np.array(x).shape) == 1 :\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=-0.009954323422670053.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-2c90f068df67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_word_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mxtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_embed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Neural Network'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-415d7496b1fe>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# If features are list of features of different sizes, standardization has to be made list-wise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-415d7496b1fe>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# If features are list of features of different sizes, standardization has to be made list-wise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[0mTransformer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \"\"\"\n\u001b[1;32m--> 696\u001b[1;33m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    697\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                                 force_all_finite='allow-nan')\n",
      "\u001b[1;32m~\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;31m# If input is scalar raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    613\u001b[0m                     \u001b[1;34m\"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=-0.009954323422670053.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "test = get_test_data('../data/')\n",
    "test = compute_word_vectors(test, embeddings, 100, vocab)\n",
    "xtest = preprocess(test.mean_embed.tolist())\n",
    "\n",
    "model = classifiers['Neural Network'][0]\n",
    "predictions = model.predict(xtest)\n",
    "create_csv_submission(test.index, predictions, '../submission/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models computed so far are the following.\n",
      " \n",
      "Classifier                                         | R2 Score            \n",
      "-----------------------------------------------------------------\n",
      "Linear Model                                       | 0.0528607913\n",
      "Logistic Regression                                | 0.5927200000\n",
      "Logistic Regression using cross-validation         | 0.5928000000\n",
      "SVM classifier                                     | 0.5940400000\n",
      "Neural Network                                     | 0.6162800000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalling classifiers \n",
    "# stored in format : 'classifier name'=(classifier, R2 score) \n",
    "\n",
    "print(f\"Models computed so far are the following.\\n \")\n",
    "print(f\"{'Classifier':50s} | {'R2 Score':20s}\")\n",
    "print(f\"-----------------------------------------------------------------\")\n",
    "for k,v in classifiers.items() :\n",
    "    print(f\"{k:50s} | {v[1]:10.10f}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Here we detail previously computed results from `results/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Dimensions evolution\n",
    "Below we detail how different metrics perform when the dimension of the word embeddings computed by GloVe algorithm changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 dimensions\n",
      "\n",
      "Accuracy : 0.585\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.574874 |   0.671121 |   0.619280\n",
      "neg        |   0.599399 |   0.497868 |   0.543936\n",
      "\n",
      "50 dimensions\n",
      "\n",
      "Accuracy : 0.5896\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.575301 |   0.671701 |   0.619775\n",
      "neg        |   0.609460 |   0.508167 |   0.554223\n",
      "\n",
      "100 dimensions\n",
      "\n",
      "Accuracy : 0.60904\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.587911 |   0.726698 |   0.649979\n",
      "neg        |   0.643141 |   0.491608 |   0.557257\n",
      "\n",
      "250 dimensions\n",
      "\n",
      "Accuracy : 0.61628\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.634955 |   0.542312 |   0.584988\n",
      "neg        |   0.602425 |   0.689859 |   0.643184\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "precs = []\n",
    "recs = []\n",
    "f1s = []\n",
    "\n",
    "\n",
    "for d in [20,50,100,250] :\n",
    "    print(f'\\n{d} dimensions\\n')\n",
    "    name = path+'metrics_'+str(local_t_size)+'_'+str(d)+'_baseline.npy'\n",
    "    r = np.load(name, allow_pickle=True)\n",
    "    r = r.item()\n",
    "    print(f\"Accuracy : {r['accuracy']}\")\n",
    "    print(f\"{'Label':10s} | {'precision':10s} | {'recall':10s} | {'f1-score':10s}\")\n",
    "    print(f\"{'pos':10s} | {r['pos']['precision']:10f} | {r['pos']['recall']:10f} | {r['pos']['f1-score']:10f}\")    \n",
    "    print(f\"{'neg':10s} | {r['neg']['precision']:10f} | {r['neg']['recall']:10f} | {r['neg']['f1-score']:10f}\")  \n",
    "    accs.append(r['accuracy'])\n",
    "    precs.append(r['pos']['precision'])\n",
    "    recs.append(r['pos']['recall'])\n",
    "    f1s.append(r['pos']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [20,50,100,250]\n",
    "plt.plot(x, accs)\n",
    "plt.plot(x, precs)\n",
    "plt.plot(x, recs)\n",
    "plt.plot(x, f1s)\n",
    "plt.legend(['accuracy','precision','recall','f1-score'])\n",
    "plt.xticks(ticks=np.arange(0,260,20))\n",
    "plt.vlines(190,ymin=0.53, ymax=0.725, color='black')\n",
    "name = '../plots/'+'metrics_'+str(local_t_size)+'_dims_baseline.png'\n",
    "plt.savefig(name, dpi=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the optimal number of dimensions seems to lie around **190** as the parameters are at their common highest at this point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
