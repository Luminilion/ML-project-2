{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained NNLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from https://www.tensorflow.org/hub/tutorials/tf2_text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Installations\n",
    "!pip install tensorflow_hub\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded POS data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Data sizes : (POS) 1250000 (NEG) 1250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '../data/'\n",
    "# Load training set\n",
    "\n",
    "pos = pd.read_table(data_path + \"train_pos_full.txt\", sep='.\\n', names=['tweet'], engine='python')\n",
    "pos['label']=1\n",
    "print(f\"Loaded POS data, correctly interpreted 1-tweet-per-line fashion : {pos.shape[0]==1_250_000}\")\n",
    "neg = pd.read_table(data_path + \"train_neg_full.txt\", sep='.\\n', names=['tweet'], engine='python')\n",
    "neg['label']=0\n",
    "print(f\"Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : {neg.shape[0]==1_250_000}\")\n",
    "print(f\"Data sizes : (POS) {pos.shape[0]} (NEG) {neg.shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because your logic is so dumb , i won't even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" &lt;user&gt; just put casper in a box ! \" looved t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; thanks sir &gt; &gt; don't trip lil ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting my brother tmr is the bestest birthda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>im so sorry ! &lt;user&gt; &amp; to &lt;user&gt; &amp; &lt;user&gt; u gu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>i can't find food coloring anywhere</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>&lt;user&gt; same here ! ! but tort ! ! wonder why y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>keyless entry remote fob clicker for 2005 buic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>&lt;user&gt; yeap . doctor don't know what's wrong w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "0        <user> i dunno justin read my mention or not ....      1\n",
       "1        because your logic is so dumb , i won't even c...      1\n",
       "2        \" <user> just put casper in a box ! \" looved t...      1\n",
       "3        <user> <user> thanks sir > > don't trip lil ma...      1\n",
       "4        visiting my brother tmr is the bestest birthda...      1\n",
       "...                                                    ...    ...\n",
       "2499995  im so sorry ! <user> & to <user> & <user> u gu...      0\n",
       "2499996                i can't find food coloring anywhere      0\n",
       "2499997  <user> same here ! ! but tort ! ! wonder why y...      0\n",
       "2499998  keyless entry remote fob clicker for 2005 buic...      0\n",
       "2499999  <user> yeap . doctor don't know what's wrong w...      0\n",
       "\n",
       "[2500000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pos.merge(neg, how='outer')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2500000,), dtype=string, numpy=\n",
       " array([b'<user> i dunno justin read my mention or not . only justin and god knows about that , but i hope you will follow me #believe 15',\n",
       "        b\"because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\",\n",
       "        b'\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch',\n",
       "        ...,\n",
       "        b'<user> same here ! ! but tort ! ! wonder why you chose crime over all the other modules hahaa trying to impressing someone are we ?',\n",
       "        b'keyless entry remote fob clicker for 2005 buick lacrosse - ( must be programmed by buick dealer price does not ... <url>',\n",
       "        b\"<user> yeap . doctor don't know what's wrong with me lol , either migraine or idk . cheer up lah . everything's gonna be okay .\"],\n",
       "       dtype=object)>,\n",
       " <tf.Tensor: shape=(2500000,), dtype=int64, numpy=array([1, 1, 1, ..., 0, 0, 0], dtype=int64)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tensor = tf.constant(tweets['tweet'].values)\n",
    "labels_tensor = tf.constant(tweets['label'].values)\n",
    "dataset = (tweets_tensor, labels_tensor)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=dataset\n",
    "train_examples, train_labels = tfds.as_numpy(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the model\n",
    "#model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "#Largest model\n",
    "model = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[128], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_2 (KerasLayer)   (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 124,646,849\n",
      "Trainable params: 124,646,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.6838 - accuracy: 0.5748 - val_loss: 0.6526 - val_accuracy: 0.7490\n",
      "Epoch 2/4\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6543 - accuracy: 0.6914 - val_loss: 0.6175 - val_accuracy: 0.8028\n",
      "Epoch 3/4\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.6235 - accuracy: 0.7179 - val_loss: 0.5940 - val_accuracy: 0.7915\n",
      "Epoch 4/4\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.5912 - accuracy: 0.7305 - val_loss: 0.5680 - val_accuracy: 0.7870\n"
     ]
    }
   ],
   "source": [
    "x_val = train_examples[:10000]\n",
    "partial_x_train = train_examples[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=4,\n",
    "                    batch_size=500000,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "## Test the model\n",
    "\n",
    "# To format the testing data\n",
    "def extract_tweet(tweet):\n",
    "    return tweet.split(\",\", 1)[1]\n",
    "\n",
    "# Load the testing data\n",
    "test = pd.read_fwf(data_path +\"test_data.txt\", sep=\"\\n\", header=None)\n",
    "test.index = pd.RangeIndex(start=1, stop=10001, step=1) # Format asked by AI Crowd\n",
    "test = test[0].map(extract_tweet)\n",
    "test = pd.DataFrame(test)\n",
    "test.columns = ['tweet']\n",
    "test\n",
    "\n",
    "test_tensor=test['tweet'].values\n",
    "\n",
    "def log_odd_convert(x):\n",
    "    return -1 if x<0 else 1\n",
    "results = list(map(lambda x:log_odd_convert(x), model.predict(test_tensor)))\n",
    "test['label']=results\n",
    "\n",
    "## Export the result\n",
    "\n",
    "test = test.drop('tweet', axis=1)\n",
    "test.index.name='Id'\n",
    "test = test.rename(columns={'label':'Prediction'})\n",
    "test\n",
    "\n",
    "with open(\"/content/gdrive/MyDrive/ML2/submission.csv\", 'w') as f:\n",
    "    test.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr = {\n",
    "  # SMS abbreviations\n",
    "  'omg': 'oh my god',\n",
    "  'afk':'away from keyboard',\n",
    "  'bf':'boyfriend',\n",
    "  'bff':'best friend forever',\n",
    "  'lol' : 'laughing out loud',\n",
    "  'irl' : 'in my opinion',\n",
    "  'gf' :'girlfriend',\n",
    "  'idk' : \"i don't know\",\n",
    "  'fyi':'for your information',\n",
    "  'asap' : 'as soon as possible',\n",
    "  'yolo':'you live only once',\n",
    "  'smh':'shaking my head',\n",
    "  'btw' : 'by the way',\n",
    "  'otw':'on the way',\n",
    "  'msg':'message',\n",
    "  'ppl' : 'people',\n",
    "  'np' : 'no problem',\n",
    "  'imy':'i miss you',\n",
    "  'jk' : 'just kidding',\n",
    "  'fyi' : 'for your information',\n",
    "  'idc' : \"i don't care\",\n",
    "  'gg' : 'good game',\n",
    "  'thx' : 'thanks',\n",
    "  'lmao' : 'laughing my ass off',\n",
    "  'ily':'i love you',\n",
    "  'rofl' : 'rolling on floor laughing',\n",
    "  'stfu' : 'shut the fuck up',\n",
    "  'y' : 'you',\n",
    "  'yolo':'you only live once',\n",
    "  'wtf' : 'what the fuck',\n",
    "  'wth':'what the hell',\n",
    "  # smileys\n",
    "  ':|' : \"i'm indecisive\",\n",
    "  ':[' : \"i'm sad\",\n",
    "  ':@' : \"i'm angry\",\n",
    "  ':{' : \"i'm sad\",\n",
    "  'xd' : \"i'm laughing\",\n",
    "  ':/' : \"i'm skeptical\",\n",
    "  ':p' : \"i'm cheeky\",\n",
    "  ':d' : \"i'm smiling\",\n",
    "  ':$' : \"i'm embarrassed\",\n",
    "  \":')\" : \"i'm joyful\",\n",
    "  '=)' : \"i'm smiling\",\n",
    "  'd:' : \"i'm smiling\",\n",
    "  'xx' : 'two kisses',\n",
    "  'xxx' : 'hugs and kisses',\n",
    "  'xoxo' : 'hugs and kisses',\n",
    "  ':o' : \"i'm surprised\",\n",
    "  '<3' : 'love'\n",
    " }\n",
    "\n",
    "def formalize(tweet):\n",
    "    return ' '.join([abbr.get(x, x) for x in tweet.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Define Preprocessors\n",
    "\n",
    "def clean_HTML_tags(series) :\n",
    "    return series.str.replace('<\\/*[a-zA-Z]+>', '', regex=True)\n",
    "\n",
    "def pretrain_process(pos_,neg_):\n",
    "    pos = pos_.copy()\n",
    "    neg = neg_.copy()\n",
    "\n",
    "    # Drop duplicates\n",
    "    pos = pos.drop_duplicates()\n",
    "    neg = neg.drop_duplicates()\n",
    "    # Balance classes after having deleted duplicates\n",
    "    min_size = min(pos.shape[0], neg.shape[0])\n",
    "    pos = resample(pos, n_samples=min_size, replace=False)\n",
    "    neg = resample(neg, n_samples=min_size, replace=False)\n",
    "\n",
    "    pos['tweet'] = clean_HTML_tags(pos['tweet']).values\n",
    "    neg['tweet'] = clean_HTML_tags(neg['tweet']).values\n",
    "    pos['tweet'] = list(map(lambda x : formalize(x), pos['tweet'].values))\n",
    "    neg['tweet'] = list(map(lambda x : formalize(x), neg['tweet'].values))\n",
    "\n",
    "    return pos.merge(neg, how='outer')\n",
    "\n",
    "def preprocessing_test(test_):\n",
    "    test = test_.copy()\n",
    "    test['tweet'] = clean_HTML_tags(test['tweet']).values\n",
    "    test['tweet'] = list(map(lambda x : formalize(x), test['tweet'].values))\n",
    "    return test\n",
    "\n",
    "tweets = pretrain_process(pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ = resample(tweets, n_samples=10_000, replace=False)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(tweets_,\n",
    "                                                                   text_column='tweet',\n",
    "                                                                   label_columns=['label'],\n",
    "                                                                   preprocess_mode='bert', \n",
    "                                                                   lang='en',\n",
    "                                                                   verbose=True\n",
    "                                                                   )\n",
    "\n",
    "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)\n",
    "learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=12)\n",
    "learner.lr_find(max_epochs=5, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training report of the best prediction\n",
    "1st cycle : 8e-4, 10'000 samples, accuracy of  0.5542  \n",
    "2nd cycle : 2e-5, 30,000 samples, accuracy of  0.8147  \n",
    "3rd cycle : 2e-5, 30,000 samples, accuracy of  0.8512  \n",
    "4th cycle : 2e-5, 30,000 samples, accuracy of  0.8554    \n",
    "5th cycle : 1e-5, 30,000 samples, accuracy of  0.8588     \n",
    "6th cycle : 1e-5, 30,000 samples, accuracy of  0.8702    \n",
    "7th cycle : 1e-5, 30,000 samples, accuracy of  0.8713     \n",
    "8th cycle : 5e-6, 30,000 samples, accuracy of  0.8695    \n",
    "9th cycle : 5e-6, 30,000 samples, accuracy of  0.8707    \n",
    "10th cycle: 5e-7, 30,000 samples, accuracy of  0.8735    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "done.\n",
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "done.\n",
      "Is Multi-Label? False\n",
      "maxlen is 400\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model \n",
    "initial_n_samples = 10_000\n",
    "\n",
    "tweets_ = resample(tweets, n_samples=initial_n_samples, replace=False)\n",
    "train_n_samples = int(initial_n_samples*(1-0.01))\n",
    "train_df = tweets_[:train_n_samples]\n",
    "test_df = tweets_[train_n_samples:]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(tweets_,\n",
    "                                                                   text_column='tweet',\n",
    "                                                                   label_columns=['label'],\n",
    "                                                                   val_df=test_df,\n",
    "                                                                   preprocess_mode='bert', \n",
    "                                                                   lang='en',\n",
    "                                                                   verbose=True\n",
    "                                                                   )\n",
    "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_cycle(model, tweets, n_samples, lr, batch_size, n_batches=1):\n",
    "'''\n",
    "Fits the model with the given parameters using a cyclical learning rate\n",
    "'''\n",
    "    tweets_ = resample(tweets, n_samples=n_samples, replace=False)\n",
    "    \n",
    "    train_n_samples = int(n_samples*(1-0.01)) # nb of training samples\n",
    "    train_df = tweets_[:train_n_samples]\n",
    "    test_df = tweets_[train_n_samples:] # Validation set\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(tweets_,\n",
    "                                                                   text_column='tweet',\n",
    "                                                                   label_columns=['label'],\n",
    "                                                                   val_df=test_df,\n",
    "                                                                   preprocess_mode='bert', \n",
    "                                                                   lang='en',\n",
    "                                                                   verbose=True\n",
    "                                                                   )\n",
    "    learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=batch_size)\n",
    "    learner.fit_onecycle(lr, n_batches)\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "done.\n",
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "done.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.5705 - accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Executing this cell many times will train the model \n",
    "\n",
    "learner = run_one_cycle(model, tweets, 10, 2e-5, 6) #default lr is 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_BS = 6\n",
    "p = ktrain.get_predictor(learner.model, preproc, batch_size=EVAL_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing data\n",
    "test = pd.read_fwf(data_path + \"test_data.txt\", sep=\"\\n\", header=None)\n",
    "# To format the testing data\n",
    "def extract_tweet(tweet):\n",
    "    return tweet.split(\",\", 1)[1]\n",
    "# Formatting for AI Crowd\n",
    "test.index = pd.RangeIndex(start=1, stop=10001, step=1) \n",
    "test = test[0].map(extract_tweet)\n",
    "test = pd.DataFrame(test)\n",
    "test.columns = ['tweet']\n",
    "test= preprocessing_test(test)\n",
    "test_values=test['tweet'].values\n",
    "# Make the predictions\n",
    "test['label']=p.predict(test_values)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the result\n",
    "test = test.drop('tweet', axis=1)\n",
    "test.index.name='Id'\n",
    "test = test.rename(columns={'label':'Prediction'})\n",
    "\n",
    "with open(data_path + \"submission.csv\", 'w') as f:\n",
    "    test.to_csv(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada2]",
   "language": "python",
   "name": "conda-env-ada2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
