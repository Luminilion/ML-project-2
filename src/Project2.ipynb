{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base parameters\n",
    "\n",
    "# Loading\n",
    "embeddings_file = 'embeddings_full_10epoch_100dim.npy'\n",
    "embeddings_files = ['embeddings_full_10epoch_250dim_part1.npy', \n",
    "                    'embeddings_full_10epoch_250dim_part2.npy', \n",
    "                    'embeddings_full_10epoch_250dim_part3.npy']\n",
    "vocab_file = 'vocab_cut.txt'\n",
    "\n",
    "# Training\n",
    "local_t_size = 100_000\n",
    "word_vectors_file_location = '../precomputed_data/'\n",
    "embeddings_dim_info = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Loading\n",
    "\n",
    "In this section we load the data for :\n",
    "* positive tweets, label= `:)` ($1$ for classification) \n",
    "* negative tweets, label= `:(` ($-1$ for classification)\n",
    "\n",
    "Full data is used below (1'250'000 tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded POS data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Number of tweets : (POS) 1250000 (NEG) 1250000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because your logic is so dumb , i won't even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" &lt;user&gt; just put casper in a box ! \" looved t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; thanks sir &gt; &gt; don't trip lil ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting my brother tmr is the bestest birthda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249995</th>\n",
       "      <td>im so sorry ! &lt;user&gt; &amp; to &lt;user&gt; &amp; &lt;user&gt; u gu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249996</th>\n",
       "      <td>i can't find food coloring anywhere</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249997</th>\n",
       "      <td>&lt;user&gt; same here ! ! but tort ! ! wonder why y...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249998</th>\n",
       "      <td>keyless entry remote fob clicker for 2005 buic...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249999</th>\n",
       "      <td>&lt;user&gt; yeap . doctor don't know what's wrong w...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "0        <user> i dunno justin read my mention or not ....      1\n",
       "1        because your logic is so dumb , i won't even c...      1\n",
       "2        \" <user> just put casper in a box ! \" looved t...      1\n",
       "3        <user> <user> thanks sir > > don't trip lil ma...      1\n",
       "4        visiting my brother tmr is the bestest birthda...      1\n",
       "...                                                    ...    ...\n",
       "1249995  im so sorry ! <user> & to <user> & <user> u gu...     -1\n",
       "1249996                i can't find food coloring anywhere     -1\n",
       "1249997  <user> same here ! ! but tort ! ! wonder why y...     -1\n",
       "1249998  keyless entry remote fob clicker for 2005 buic...     -1\n",
       "1249999  <user> yeap . doctor don't know what's wrong w...     -1\n",
       "\n",
       "[2500000 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "\n",
    "## Load full training sets\n",
    "# positive\n",
    "pos = pd.read_table(data_path+'train_pos_full.txt', sep='.\\n', names=['tweet'], engine='python')\n",
    "pos['label']=1\n",
    "print(f\"Loaded POS data, correctly interpreted 1-tweet-per-line fashion : {pos.shape[0]==1_250_000}\")\n",
    "\n",
    "# negative\n",
    "neg = pd.read_table(data_path+'train_neg_full.txt', sep='.\\n', names=['tweet'], engine='python')\n",
    "neg['label']=-1\n",
    "print(f\"Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : {neg.shape[0]==1_250_000}\")\n",
    "\n",
    "# Data sizes\n",
    "print(f\"Number of tweets : (POS) {pos.shape[0]} (NEG) {neg.shape[0]}\\n\")\n",
    "\n",
    "# Merge datasets to get a complete training set\n",
    "tweets = pos.append(neg)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word embeddings in structure of type <class 'numpy.ndarray'>.\n",
      "Loaded word embeddings in structure of type <class 'pandas.core.series.Series'>.\n",
      "\n",
      "Both the embeddings and the vocabulary are same length :  True\n",
      "Embeddings: (101298, 250), vocab: (101298,)\n",
      "NA values were dropped in both tables: True\n",
      "Embeddings: (101296, 250), vocab: (101296,)\n"
     ]
    }
   ],
   "source": [
    "## Load word embeddings and vocabulary to compute word vectors of tweets\n",
    "\n",
    "from glove_helper import concatenate\n",
    "\n",
    "# Load word embeddings\n",
    "#embeddings = np.load(data_path + embeddings_file)\n",
    "embeddings = concatenate(embeddings_files)\n",
    "print(f'Loaded word embeddings in structure of type {type(embeddings)}.')\n",
    "\n",
    "# Loading vocab\n",
    "words = pd.read_table(data_path + vocab_file, sep='.\\n', names=['word'], engine='python', squeeze=True, na_values=np.nan)\n",
    "print(f'Loaded word embeddings in structure of type {type(words)}.')\n",
    "\n",
    "# Check that the vocabulary encompasses all embedded words\n",
    "print(f'\\nBoth the embeddings and the vocabulary are same length :  {len(embeddings)==words.shape[0]}')\n",
    "print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")\n",
    "\n",
    "## Clean the data\n",
    "\n",
    "# Drop NaN values in words\n",
    "nas = words.isna()\n",
    "words.dropna(inplace=True)\n",
    "embeddings = np.delete(embeddings, nas[nas].index.values, axis=0)\n",
    "print(f'NA values were dropped in both tables: {len(embeddings)==words.shape[0]}')\n",
    "print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")\n",
    "\n",
    "# Index by words for faster index-for-word search\n",
    "words = pd.DataFrame(data=words.index, index=words.values)\n",
    "embeddings = pd.DataFrame(embeddings, index=words.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>0.030608</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>-0.022513</td>\n",
       "      <td>-0.017231</td>\n",
       "      <td>-0.034461</td>\n",
       "      <td>-0.014330</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>-0.004809</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025114</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.035728</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-0.009736</td>\n",
       "      <td>0.004291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.026680</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>-0.020617</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>-0.040572</td>\n",
       "      <td>-0.020867</td>\n",
       "      <td>0.016749</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>-0.010314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012885</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>-0.005833</td>\n",
       "      <td>0.041469</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>-0.009862</td>\n",
       "      <td>-0.017096</td>\n",
       "      <td>0.026434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.014688</td>\n",
       "      <td>-0.013984</td>\n",
       "      <td>-0.026582</td>\n",
       "      <td>-0.021369</td>\n",
       "      <td>-0.024164</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>-0.015996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>-0.013011</td>\n",
       "      <td>-0.010744</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.007297</td>\n",
       "      <td>-0.004335</td>\n",
       "      <td>0.014034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>-0.007684</td>\n",
       "      <td>-0.018878</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>-0.015549</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015088</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.017208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.017482</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.015768</td>\n",
       "      <td>-0.031900</td>\n",
       "      <td>-0.015413</td>\n",
       "      <td>-0.015017</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>-0.010443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>-0.024197</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>-0.013506</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>-0.021917</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>-0.039720</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.025413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "<user>  0.030608  0.007450 -0.022513 -0.017231 -0.034461 -0.014330 -0.002676   \n",
       "!       0.026680  0.005015 -0.020617  0.004282 -0.040572 -0.020867  0.016749   \n",
       "i       0.014688 -0.013984 -0.026582 -0.021369 -0.024164  0.018397  0.003230   \n",
       "the     0.010400  0.008356 -0.001788 -0.007684 -0.018878  0.004186 -0.015549   \n",
       ".       0.017482 -0.000450  0.004069  0.015768 -0.031900 -0.015413 -0.015017   \n",
       "\n",
       "             7         8         9    ...       240       241       242  \\\n",
       "<user>  0.003208 -0.004809 -0.001972  ...  0.025114  0.019413 -0.004826   \n",
       "!       0.020033  0.013227 -0.010314  ... -0.012885 -0.005479  0.031890   \n",
       "i       0.006048  0.016579 -0.015996  ...  0.000506  0.007428  0.012523   \n",
       "the     0.019104  0.019345 -0.000396  ...  0.015088  0.009353  0.002282   \n",
       ".       0.017963  0.000415 -0.010443  ...  0.024620 -0.024197  0.014449   \n",
       "\n",
       "             243       244       245       246       247       248       249  \n",
       "<user> -0.035728  0.050963 -0.000578  0.016071 -0.030458 -0.009736  0.004291  \n",
       "!      -0.005833  0.041469  0.021345  0.000286 -0.009862 -0.017096  0.026434  \n",
       "i      -0.013011 -0.010744  0.001525  0.000069 -0.007297 -0.004335  0.014034  \n",
       "the     0.010725  0.010405 -0.006667  0.014612  0.016108  0.006544  0.017208  \n",
       ".      -0.013506  0.002333 -0.021917  0.005908 -0.039720  0.000138 -0.025413  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "<user>  0\n",
       "!       1\n",
       "i       2\n",
       "the     3\n",
       ".       4"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploratory Data Analysis\n",
    "In this part we analyse our data in order to optimize its information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning tags \n",
    "Here we explore the non-spoken tags present in the tweets and determine if they are relevant for our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|KEY           |POS   |NEG   |\n",
      "|<joke>        |     1|     0|\n",
      "|<w>           |     0|     1|\n",
      "|<parenthood>  |     0|     1|\n",
      "|<content>     |     0|     1|\n",
      "|<agent>       |     0|     3|\n",
      "|<del>         |     0|     1|\n",
      "|<strong>      |     0|     6|\n",
      "|<b>           |     1|    26|\n",
      "|<hot>         |     1|     0|\n",
      "|<hugs>        |     1|     1|\n",
      "|<space>       |     3|     0|\n",
      "|<retweet>     |     0|     1|\n",
      "|<sigh>        |     0|     3|\n",
      "|<br>          |     1|     6|\n",
      "|</html>       |     0|     1|\n",
      "|<blushing>    |     1|     0|\n",
      "|</joke>       |     1|     0|\n",
      "|<ht>          |     0|     1|\n",
      "|<emotional>   |     0|     1|\n",
      "|<iostream>    |     0|     1|\n",
      "|<please>      |     0|     1|\n",
      "|<weirdarms>   |     1|     0|\n",
      "|<sarah>       |     1|     0|\n",
      "|<blink>       |     0|     1|\n",
      "|<ummm>        |     0|     1|\n",
      "|<user>        |1027205|578390|\n",
      "|</div>        |     0|     1|\n",
      "|<em>          |     0|     2|\n",
      "|<p>           |     0|    16|\n",
      "|<justkiddin>  |     0|     1|\n",
      "|<waves>       |     1|     0|\n",
      "|</summary>    |     1|     0|\n",
      "|<trans>       |     0|     3|\n",
      "|</del>        |     0|     1|\n",
      "|<understood>  |     1|     0|\n",
      "|<cont>        |     1|     0|\n",
      "|<outstanding> |     1|     0|\n",
      "|<brr>         |     1|     0|\n",
      "|<thing>       |     0|     1|\n",
      "|</script>     |     0|     4|\n",
      "|<o>           |     0|     1|\n",
      "|</cfoutput>   |     0|     1|\n",
      "|<name>        |     0|     1|\n",
      "|<demon>       |     0|     1|\n",
      "|<ducks>       |     1|     0|\n",
      "|<summary>     |     1|     0|\n",
      "|</strong>     |     0|     6|\n",
      "|<i>           |     0|    10|\n",
      "|<calc>        |     1|     0|\n",
      "|<c>           |     1|     2|\n",
      "|<update>      |     0|     2|\n",
      "|<time>        |     1|     0|\n",
      "|<mournfully>  |     0|     1|\n",
      "|<moan>        |     0|     1|\n",
      "|<gardenstuff> |     2|     0|\n",
      "|</span>       |     0|     1|\n",
      "|<popcorn>     |     1|     0|\n",
      "|</popcorn>    |     1|     0|\n",
      "|</details>    |     1|     0|\n",
      "|</a>          |     1|     7|\n",
      "|<g>           |     1|     0|\n",
      "|<here>        |     1|     0|\n",
      "|<syrian>      |     0|     6|\n",
      "|<hahahahhahaha>|     0|     1|\n",
      "|</i>          |     0|    11|\n",
      "|</moan>       |     0|     1|\n",
      "|<twinkle>     |     0|     1|\n",
      "|</body>       |     0|     1|\n",
      "|<sciencestuff>|     2|     0|\n",
      "|<attention>   |     0|     2|\n",
      "|<ages>        |     0|     1|\n",
      "|</em>         |     0|     2|\n",
      "|<mikel>       |     1|     0|\n",
      "|<atomic>      |     0|     1|\n",
      "|<screams>     |     0|     1|\n",
      "|<haha>        |     0|     1|\n",
      "|</b>          |     1|    19|\n",
      "|<laugh>       |     1|     0|\n",
      "|<thx>         |     1|     0|\n",
      "|<naive>       |     0|     1|\n",
      "|<impressive>  |     1|     0|\n",
      "|<script>      |     0|     2|\n",
      "|<likewise>    |     1|     0|\n",
      "|<ducking>     |     1|     0|\n",
      "|<weeping>     |     0|     1|\n",
      "|<grin>        |     2|     0|\n",
      "|<dynamic>     |     1|     0|\n",
      "|<url>         | 98886|427976|\n",
      "|<cfoutput>    |     0|     1|\n",
      "|<grunt>       |     1|     0|\n",
      "|<cutestuff>   |     2|     0|\n",
      "\n",
      "POS tweets contain 1126137 (11.88%) HTML tags.\n",
      "NEG tweets contain 1006539 (-10.62%) HTML tags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "## We check if the tags are relevant information between both pos and neg cases\n",
    "\n",
    "def count_HTML_tags(series) :\n",
    "    \"\"\"\n",
    "    Returns stats about the HTML tags in the tweet series.\n",
    "    Returns :\n",
    "    dic (defaultdict) : dict of all tags occurences.\n",
    "    count (int) : count of all tags.\"\"\"\n",
    "    dic = defaultdict(lambda:0)\n",
    "    def a(k):\n",
    "        dic[k]+=1\n",
    "        return None\n",
    "    series.apply(lambda s : [a(k) for k in re.findall('<\\/*[a-zA-Z]+>', s)])\n",
    "    count = series.str.count('<\\/*[a-zA-Z]+>').sum()\n",
    "    return dic, count\n",
    "\n",
    "# We query stats about the tags\n",
    "d_pos, n_pos = count_HTML_tags(pos['tweet'])\n",
    "d_neg, n_neg = count_HTML_tags(neg['tweet'])\n",
    "all_keys = set(d_pos.keys()) | set(d_neg.keys())\n",
    "\n",
    "print(f\"|{'KEY':14s}|{'POS':6s}|{'NEG':6s}|\")\n",
    "for k in all_keys : \n",
    "    print(f\"|{k:14s}|{d_pos[k]:6d}|{d_neg[k]:6d}|\")\n",
    "\n",
    "print(f\"\\nPOS tweets contain {n_pos} ({(n_pos-n_neg)*100/n_neg:.2f}%) HTML tags.\")\n",
    "print(f\"NEG tweets contain {n_neg} ({(n_neg-n_pos)*100/n_pos:.2f}%) HTML tags.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Although the difference in number of tags is not significant. The distribution of them is quite significant (i.e. for tags `<url>` and `<user>`). Thus we choose to leave the tags as part of the tweet. **THIS COULD BE REVIEWED TO IMPROVE PERF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the HTML tags from the tweets\n",
    "## CHANGE RETURN VAR IF RELEVANT\n",
    "\n",
    "def clean_HTML_tags(series) :\n",
    "    return series.str.replace('<\\/*[a-zA-Z]+>', '', regex=True)\n",
    "\n",
    "t = clean_HTML_tags(pos['tweet'])\n",
    "t2 = clean_HTML_tags(neg['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "In this part we train the models on our data.\n",
    "Thus, we perform\n",
    "* a resampling of our data to work locally on a smaller set.\n",
    "* the creation of word vectors for our tweets.\n",
    "* a train-test-split to locally estimate the model's performance.\n",
    "* cross-validation trainin on a series of models :\n",
    "    * Linear Regression\n",
    "    * Logistic Regression\n",
    "    * SVM\n",
    "    * Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the Training set\n",
    "Using only a set of 200'000 tweets locally to decrease computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303671</th>\n",
       "      <td>&lt;user&gt; welcome to my world and in response to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15833</th>\n",
       "      <td>makasi mas tyo rt &lt;user&gt; happy birthday cantik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414656</th>\n",
       "      <td>&lt;user&gt; omg omg omg there so good ... yeah fuck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634143</th>\n",
       "      <td>#harrylovesbabylux that lil baby just wont sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5880</th>\n",
       "      <td>greyson chance , iloveyou &lt;3 though im not a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859225</th>\n",
       "      <td>i have zero plans for this weekend . sad times</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209473</th>\n",
       "      <td>that walk of shame when you throw something to...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532034</th>\n",
       "      <td>caught up with a bad cold ... i hate being sic...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116662</th>\n",
       "      <td>&lt;user&gt; follow me ? been trying to get you to n...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573562</th>\n",
       "      <td>&lt;user&gt; ooohhh . h ... ikr .. ! ? ! how sad i a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "303671   <user> welcome to my world and in response to ...      1\n",
       "15833    makasi mas tyo rt <user> happy birthday cantik...      1\n",
       "414656   <user> omg omg omg there so good ... yeah fuck...      1\n",
       "634143   #harrylovesbabylux that lil baby just wont sto...      1\n",
       "5880     greyson chance , iloveyou <3 though im not a b...      1\n",
       "...                                                    ...    ...\n",
       "859225      i have zero plans for this weekend . sad times     -1\n",
       "1209473  that walk of shame when you throw something to...     -1\n",
       "532034   caught up with a bad cold ... i hate being sic...     -1\n",
       "116662   <user> follow me ? been trying to get you to n...     -1\n",
       "573562   <user> ooohhh . h ... ikr .. ! ? ! how sad i a...     -1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Take only `0.5*local_t_size` samples from both classes for faster computation\n",
    "n = int(local_t_size/2)\n",
    "pos_ = resample(pos, n_samples=n, replace=False)\n",
    "neg_ = resample(neg, n_samples=n, replace=False)\n",
    "tweets_ = pos_.append(neg_)\n",
    "\n",
    "tweets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for 101,296.0 with 250 features for each word.\n",
      "Embeddings shape : (101296, 250).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>0.030608</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>-0.022513</td>\n",
       "      <td>-0.017231</td>\n",
       "      <td>-0.034461</td>\n",
       "      <td>-0.014330</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>-0.004809</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025114</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.035728</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-0.009736</td>\n",
       "      <td>0.004291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.026680</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>-0.020617</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>-0.040572</td>\n",
       "      <td>-0.020867</td>\n",
       "      <td>0.016749</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>-0.010314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012885</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>-0.005833</td>\n",
       "      <td>0.041469</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>-0.009862</td>\n",
       "      <td>-0.017096</td>\n",
       "      <td>0.026434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "<user>  0.030608  0.007450 -0.022513 -0.017231 -0.034461 -0.014330 -0.002676   \n",
       "!       0.026680  0.005015 -0.020617  0.004282 -0.040572 -0.020867  0.016749   \n",
       "\n",
       "             7         8         9    ...       240       241       242  \\\n",
       "<user>  0.003208 -0.004809 -0.001972  ...  0.025114  0.019413 -0.004826   \n",
       "!       0.020033  0.013227 -0.010314  ... -0.012885 -0.005479  0.031890   \n",
       "\n",
       "             243       244       245       246       247       248       249  \n",
       "<user> -0.035728  0.050963 -0.000578  0.016071 -0.030458 -0.009736  0.004291  \n",
       "!      -0.005833  0.041469  0.021345  0.000286 -0.009862 -0.017096  0.026434  \n",
       "\n",
       "[2 rows x 250 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall our data\n",
    "print(f\"Embeddings for {embeddings.shape[0]:,.1f} with {embeddings.shape[1]} features for each word.\") \n",
    "print(f'Embeddings shape : {embeddings.shape}.\\n')\n",
    "embeddings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tweet):\n",
    "    \"\"\"\n",
    "    Creates the feature vector corresponding to the tweet.\n",
    "    To do so, computes the mean of the word embeddings corresponding to the vocabulary words in the tweet.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    tweet : str\n",
    "        Input tweet from which the word vector is created.\n",
    "    \"\"\"\n",
    "    split_by_words = tweet.split()\n",
    "    embed_list = []\n",
    "    \n",
    "    # Get vocab word embeddings\n",
    "    for w in split_by_words:\n",
    "        if w in words.index :\n",
    "            embed_list.append(  embeddings.loc[w].values  )\n",
    "        \n",
    "    # Compute mean if any vocab word was found\n",
    "    mean = np.zeros(embeddings_dim_info) if not embed_list else np.mean(embed_list, axis=0) \n",
    "    return mean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import cpu_count, Pool\n",
    " \n",
    "cores = cpu_count() #Number of CPU cores on your system\n",
    "partitions = cores #Define as many partitions as you want\n",
    " \n",
    "def parallelize(data, func):\n",
    "    \"\"\"\n",
    "    Uses all CPU cores available to compute the function on each element of the data.\n",
    "    \"\"\"\n",
    "    print(f\"Computing function on {cores} cores.\")\n",
    "    data_split = np.array_split(data, partitions)\n",
    "    print(data_split)\n",
    "    pool = Pool(cores)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "import ctypes, os\n",
    "# Checking if the process is executed as admin (multiprocessing does not work otherwise) \n",
    "def isAdmin():\n",
    "    \"\"\"\n",
    "    Verifies if the process is executed as administrator.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        is_admin = (os.getuid() == 0)\n",
    "    except AttributeError:\n",
    "        is_admin = ctypes.windll.shell32.IsUserAnAdmin() != 0\n",
    "    return is_admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load word vectors from ../precomputed_data/word_vectors_100000_250.npy\n",
      "Could not load word vectors from file...\n",
      "Recomputing word vectors...\n",
      "Process is not run as admin. Cannot run parallelized setting, running as sequential...\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pandas.errors import MergeError\n",
    "\n",
    "try :\n",
    "    # Load pre-computed word vectors file if possible \n",
    "    name = word_vectors_file_location+'word_vectors_'+str(local_t_size)+'_'+str(embeddings_dim_info)+'.npy'\n",
    "    print(f\"Trying to load word vectors from {name}\")\n",
    "    precomputed = np.load(name, allow_pickle=True)\n",
    "    \n",
    "    # Transform into Dataframe for merge\n",
    "    precomputed = pd.DataFrame(precomputed, columns=['index', 'label', 'mean_embed'])\n",
    "    pos_ = pos.loc[precomputed.loc[precomputed['label']==1, 'index']]\n",
    "    neg_ = neg.loc[precomputed.loc[precomputed['label']==-1, 'index']]\n",
    "    tweets_ = pos_.append(neg_).reset_index()\n",
    "    tweets_ = tweets_.merge(precomputed, how='inner', on=['index', 'label'], validate='1:1').set_index('index')\n",
    "    print('Successfully loaded from file!')\n",
    "    \n",
    "except (FileNotFoundError) as e :\n",
    "    # Create word vectors for the local dataset\n",
    "    \n",
    "    print('Could not load word vectors from file...\\nRecomputing word vectors...')\n",
    "    if isAdmin():\n",
    "        print('Process is run as admin. Running parallelized computation...')\n",
    "        tweets_['mean_embed']= parallelize(tweets_['tweet'], word_vector)\n",
    "    else : \n",
    "        print('Process is not run as admin. Cannot run parallelized setting, running as sequential...')\n",
    "        tweets_['mean_embed']= tweets_['tweet'].map(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303671</th>\n",
       "      <td>&lt;user&gt; welcome to my world and in response to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04323617223241636, -0.04555828418653311, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15833</th>\n",
       "      <td>makasi mas tyo rt &lt;user&gt; happy birthday cantik...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.06666694688033596, -0.20543962153733858, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414656</th>\n",
       "      <td>&lt;user&gt; omg omg omg there so good ... yeah fuck...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.11812069576897961, -0.025391435213531655, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634143</th>\n",
       "      <td>#harrylovesbabylux that lil baby just wont sto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.20983979778239076, -0.04064601727742977, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5880</th>\n",
       "      <td>greyson chance , iloveyou &lt;3 though im not a b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.07484689222877446, 0.035936537179757665, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859225</th>\n",
       "      <td>i have zero plans for this weekend . sad times</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.03088842861582195, 0.010422051497274737, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209473</th>\n",
       "      <td>that walk of shame when you throw something to...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.10580703961486544, -0.020836730216565093, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532034</th>\n",
       "      <td>caught up with a bad cold ... i hate being sic...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.09054672638028478, -0.02372491584675385, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116662</th>\n",
       "      <td>&lt;user&gt; follow me ? been trying to get you to n...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.10962835508327179, -0.026940459394511933, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573562</th>\n",
       "      <td>&lt;user&gt; ooohhh . h ... ikr .. ! ? ! how sad i a...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.04292668568593911, -0.01727898598251291, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label  \\\n",
       "303671   <user> welcome to my world and in response to ...      1   \n",
       "15833    makasi mas tyo rt <user> happy birthday cantik...      1   \n",
       "414656   <user> omg omg omg there so good ... yeah fuck...      1   \n",
       "634143   #harrylovesbabylux that lil baby just wont sto...      1   \n",
       "5880     greyson chance , iloveyou <3 though im not a b...      1   \n",
       "...                                                    ...    ...   \n",
       "859225      i have zero plans for this weekend . sad times     -1   \n",
       "1209473  that walk of shame when you throw something to...     -1   \n",
       "532034   caught up with a bad cold ... i hate being sic...     -1   \n",
       "116662   <user> follow me ? been trying to get you to n...     -1   \n",
       "573562   <user> ooohhh . h ... ikr .. ! ? ! how sad i a...     -1   \n",
       "\n",
       "                                                mean_embed  \n",
       "303671   [0.04323617223241636, -0.04555828418653311, -0...  \n",
       "15833    [0.06666694688033596, -0.20543962153733858, 0....  \n",
       "414656   [0.11812069576897961, -0.025391435213531655, -...  \n",
       "634143   [0.20983979778239076, -0.04064601727742977, -0...  \n",
       "5880     [0.07484689222877446, 0.035936537179757665, -0...  \n",
       "...                                                    ...  \n",
       "859225   [0.03088842861582195, 0.010422051497274737, -0...  \n",
       "1209473  [0.10580703961486544, -0.020836730216565093, -...  \n",
       "532034   [0.09054672638028478, -0.02372491584675385, -0...  \n",
       "116662   [0.10962835508327179, -0.026940459394511933, -...  \n",
       "573562   [0.04292668568593911, -0.01727898598251291, -0...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word vectors file to gain time\n",
    "word_vectors = tweets_[['label', 'mean_embed']].reset_index()\n",
    "name = word_vectors_file_location+'word_vectors_'+str(local_t_size)+'_'+str(embeddings_dim_info)\n",
    "\n",
    "np.save(name, word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split for our local dataset\n",
    "We divide our local training set into a 75% training set and a 25% local testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local training set size : (75000, 3).\n",
      "Local testing set size : (25000, 3).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_, test_ = train_test_split(tweets_, test_size=0.25)\n",
    "print(f\"Local training set size : {train_.shape}.\")\n",
    "print(f\"Local testing set size : {test_.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.25004722802119916,\n",
       "  0.05621947578270538,\n",
       "  -0.04594700842816053,\n",
       "  -0.11611114743829379,\n",
       "  -0.23047695769425885,\n",
       "  -0.11104897790986401,\n",
       "  -0.07037554743691621,\n",
       "  -0.01982821346397826,\n",
       "  -0.27603403475051486,\n",
       "  0.14812851625355478,\n",
       "  0.0027356050312975838,\n",
       "  0.2096686335401045,\n",
       "  0.002229503647915877,\n",
       "  0.0868724457424761,\n",
       "  -0.052986296191742735,\n",
       "  0.14256925377637536,\n",
       "  0.18174766318947577,\n",
       "  0.04701597446368961,\n",
       "  -0.09466080041879091,\n",
       "  0.007770308680682174,\n",
       "  0.014281595373595208,\n",
       "  -0.05764733546108451,\n",
       "  0.1987868547995471,\n",
       "  -0.1500134675122518,\n",
       "  -0.13492328454263786,\n",
       "  -0.017533417771965418,\n",
       "  -0.14324897406302123,\n",
       "  0.0452092134653261,\n",
       "  0.0890730030062575,\n",
       "  0.0820013342339635,\n",
       "  -0.1832182671707876,\n",
       "  -0.008927608421097279,\n",
       "  -0.025951350938155593,\n",
       "  0.282954638101138,\n",
       "  0.05025753294121753,\n",
       "  0.0012051225135870861,\n",
       "  -0.2285744518583992,\n",
       "  -0.08931905981365913,\n",
       "  -0.20816925095073496,\n",
       "  -0.23011759171988833,\n",
       "  -0.05536258911009935,\n",
       "  0.008743777657437503,\n",
       "  -0.005064229889711523,\n",
       "  0.0625743627774398,\n",
       "  0.1938971474724093,\n",
       "  -0.18304427487429537,\n",
       "  0.2583208263261245,\n",
       "  0.002983063933352368,\n",
       "  0.07773048135745157,\n",
       "  -0.0055577878196745095,\n",
       "  -0.21979283263261076,\n",
       "  0.19098659414161726,\n",
       "  -0.09060503918328403,\n",
       "  0.07873834334330845,\n",
       "  0.15713530122752167,\n",
       "  -0.0772235566882322,\n",
       "  -0.08477200171487319,\n",
       "  -0.13805395111896662,\n",
       "  -0.006816771600123364,\n",
       "  0.05290745978653264,\n",
       "  -0.11665406918647818,\n",
       "  0.19941157428906003,\n",
       "  0.10957943323358339,\n",
       "  -0.28703662870999647,\n",
       "  -0.001174285679184984,\n",
       "  -0.1818878870275709,\n",
       "  -0.14416590538597054,\n",
       "  0.07382745104749323,\n",
       "  0.08046780423192386,\n",
       "  -0.20452467273346486,\n",
       "  0.1819496145704194,\n",
       "  -0.15935057123323676,\n",
       "  -0.11835677355704315,\n",
       "  -0.007126909360200362,\n",
       "  -0.1152846713934617,\n",
       "  0.12655044594911993,\n",
       "  0.005608989937984974,\n",
       "  -0.13587201046565836,\n",
       "  0.1829948028958992,\n",
       "  0.19324046208402468,\n",
       "  0.1982640622227468,\n",
       "  -0.05056402948794627,\n",
       "  -0.36662785129337705,\n",
       "  -0.02885047209150815,\n",
       "  0.13936516751943834,\n",
       "  0.024746318730061317,\n",
       "  0.0034802099308658316,\n",
       "  0.061011119305382146,\n",
       "  -0.18902479060145153,\n",
       "  -0.1791553043947584,\n",
       "  -0.1585148837466028,\n",
       "  0.29478859713885475,\n",
       "  0.07815056990039876,\n",
       "  -0.058048392639657685,\n",
       "  0.23055198657937873,\n",
       "  0.19049413984112457,\n",
       "  -0.0951644654189743,\n",
       "  0.31935925414100186,\n",
       "  -0.23404479392303826,\n",
       "  -0.0827171015182851,\n",
       "  0.1941576595567384,\n",
       "  0.2090255540381972,\n",
       "  0.011615582579603849,\n",
       "  0.04558922469222188,\n",
       "  -0.074457725334454,\n",
       "  -0.17704162990815617,\n",
       "  0.19185319943135934,\n",
       "  -0.15797815448128982,\n",
       "  0.17372864887331974,\n",
       "  -0.20537013394646192,\n",
       "  0.19815744720999215,\n",
       "  0.09154452205167303,\n",
       "  0.03010848548935602,\n",
       "  -0.3180873958398795,\n",
       "  -0.10989127763890043,\n",
       "  0.02750601633451653,\n",
       "  0.09121552921598472,\n",
       "  0.031132777437749587,\n",
       "  -0.22641778345658872,\n",
       "  0.1296490004148081,\n",
       "  -0.05824473265538721,\n",
       "  0.1353499162845529,\n",
       "  -0.16590945629831041,\n",
       "  0.04423048244507706,\n",
       "  -0.19392319222182114,\n",
       "  0.09052420827100868,\n",
       "  -0.07232128967508519,\n",
       "  0.07788268427114083,\n",
       "  0.13083302853917808,\n",
       "  -0.017661605544521123,\n",
       "  -0.10435600468687578,\n",
       "  0.32738558457540334,\n",
       "  0.007797550046644471,\n",
       "  0.017255432504358435,\n",
       "  0.3227364235244411,\n",
       "  -0.16158826241415766,\n",
       "  -0.06243313734532295,\n",
       "  -0.16351247321436055,\n",
       "  0.010802818293429847,\n",
       "  -0.05715249104864421,\n",
       "  -0.23795663563154648,\n",
       "  0.3453867280981863,\n",
       "  0.10566536087994134,\n",
       "  0.1209618654885469,\n",
       "  0.0792554460214621,\n",
       "  0.11701163921310612,\n",
       "  0.23636184539654934,\n",
       "  0.10465778974939484,\n",
       "  0.13001734782754124,\n",
       "  0.182001794498276,\n",
       "  -0.1455830668815838,\n",
       "  -0.06882513959771931,\n",
       "  0.2096658347910158,\n",
       "  0.34483319576722904,\n",
       "  0.125309695175147,\n",
       "  0.22456139710779813,\n",
       "  0.3591779227215317,\n",
       "  -0.03867216460751777,\n",
       "  0.034536134882425476,\n",
       "  0.19624087767750797,\n",
       "  0.08113666323296491,\n",
       "  -0.05791828923162402,\n",
       "  -0.1619729637604887,\n",
       "  -0.09145441746314198,\n",
       "  -0.07513212315493187,\n",
       "  -0.21814678293205172,\n",
       "  0.45477735483668036,\n",
       "  0.236277026668616,\n",
       "  0.008192692842505598,\n",
       "  0.08658661440032468,\n",
       "  -0.15418087529472024,\n",
       "  0.09411796420083254,\n",
       "  -0.19339986303691198,\n",
       "  0.09977324056414355,\n",
       "  0.03472464862432944,\n",
       "  0.18445154455210033,\n",
       "  0.21671589885776,\n",
       "  -0.1075478063966806,\n",
       "  -0.1242407900807708,\n",
       "  0.011374135477249084,\n",
       "  -0.01683064882065686,\n",
       "  -0.04752617450514998,\n",
       "  0.01320597072249946,\n",
       "  -0.005100264280018503,\n",
       "  0.07960282331304551,\n",
       "  -0.1251887463185458,\n",
       "  0.0420731593638811,\n",
       "  -0.08501324449316207,\n",
       "  0.041656165052926075,\n",
       "  -0.059184400120994074,\n",
       "  -0.08143475439802506,\n",
       "  0.18889946405178076,\n",
       "  -0.09542570852535068,\n",
       "  0.1151313775860801,\n",
       "  -0.1561203966607425,\n",
       "  -0.08346127234862677,\n",
       "  0.10580315174790933,\n",
       "  -0.028430531126961173,\n",
       "  -0.041322557570162156,\n",
       "  0.021450006995573964,\n",
       "  -0.059770279504595916,\n",
       "  -0.06435016904830468,\n",
       "  0.08618969442538725,\n",
       "  0.03414086311476267,\n",
       "  0.019738715608386782,\n",
       "  -0.029039514043288465,\n",
       "  0.08802180086488244,\n",
       "  0.0001287298005911621,\n",
       "  0.2639593122460639,\n",
       "  0.036093121417109846,\n",
       "  -0.06792062615961972,\n",
       "  -0.14984026250512933,\n",
       "  -0.21282760075197796,\n",
       "  -0.07805589089955055,\n",
       "  -0.30853087272003255,\n",
       "  -0.16620718490521955,\n",
       "  0.08739475024235956,\n",
       "  0.05799859032373352,\n",
       "  -0.1289604510911721,\n",
       "  0.14268310340878007,\n",
       "  0.14767775443489567,\n",
       "  0.11227440318167596,\n",
       "  0.2677278842392974,\n",
       "  0.0037836588004366905,\n",
       "  -0.005467131863958599,\n",
       "  -0.0733030299197609,\n",
       "  0.0013604328781291562,\n",
       "  -0.28762621476832617,\n",
       "  0.0029591153804560595,\n",
       "  -0.03873340604806573,\n",
       "  0.04303505894174399,\n",
       "  0.06466090185958984,\n",
       "  -0.2272756743176298,\n",
       "  0.3696856765470019,\n",
       "  -0.12385499256438023,\n",
       "  0.1110605551895782,\n",
       "  0.13177859937910907,\n",
       "  0.10098900759601873,\n",
       "  -0.22340226270532182,\n",
       "  0.10386381274484882,\n",
       "  0.09269042074328723,\n",
       "  -0.10048899494858698,\n",
       "  -0.29972537027386265,\n",
       "  0.09340277895992155,\n",
       "  0.03052606133759312,\n",
       "  0.04941716744516387,\n",
       "  -0.21187007436758015,\n",
       "  0.047871669905530344,\n",
       "  0.16893984996705608,\n",
       "  -0.07239027092044323]]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features and label datasets\n",
    "xtrain_, ytrain_ = train_.mean_embed.copy().tolist(), train_.label.copy().to_list()\n",
    "xtest_, ytest_ = test_.mean_embed.copy().tolist(), test_.label.copy().tolist()\n",
    "\n",
    "xtest_[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing\n",
    "Here we compute our pre-processing on features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "def preprocess(X) :\n",
    "    x=X.copy()\n",
    "    \n",
    "    # Standardize data\n",
    "    standardizer=StandardScaler().fit_transform(x)\n",
    "    \n",
    "    # TODO Polynomial features and interactions\n",
    "    \n",
    "    # other data preprocessing\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process training set\n",
    "\n",
    "xtrain_ = preprocess(xtrain_)\n",
    "xtest_ = preprocess(xtest_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating efficiency of model\n",
    "Here we define metrics for model classification efficiency.\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Training\n",
    "* Linear Regression\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Linear Model is 0.0528607913232263.\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Linear Regression\n",
    "name = 'Linear Model'\n",
    "\n",
    "linear_classifier = LinearRegression().fit(xtrain_, ytrain_)\n",
    "score = linear_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (linear_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Logistic Regression is 0.59272.\n",
      "R2 score for Logistic Regression model using cross-validation is 0.5928.\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Logistic Regression\n",
    "name = 'Logistic Regression'\n",
    "\n",
    "logistic_classifier = LogisticRegression().fit(xtrain_, ytrain_)\n",
    "score = logistic_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (logistic_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} is {score}.\")\n",
    "\n",
    "# Logistic Regression using Crossvalidation\n",
    "name = 'Logistic Regression using cross-validation'\n",
    "\n",
    "logisticCV_classifier = LogisticRegressionCV().fit(xtrain_, ytrain_)\n",
    "score = logisticCV_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (logisticCV_classifier, score)\n",
    "\n",
    "print(f\"R2 score for Logistic Regression model using cross-validation is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos    0.57472   0.70490   0.63319     12467\n",
      "         neg    0.62107   0.48113   0.54222     12533\n",
      "\n",
      "    accuracy                        0.59272     25000\n",
      "   macro avg    0.59790   0.59302   0.58770     25000\n",
      "weighted avg    0.59796   0.59272   0.58758     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predtest_ = logistic_classifier.predict(xtest_)\n",
    "\n",
    "report = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos    0.57441   0.70803   0.63426     12467\n",
      "         neg    0.62213   0.47818   0.54074     12533\n",
      "\n",
      "    accuracy                        0.59280     25000\n",
      "   macro avg    0.59827   0.59310   0.58750     25000\n",
      "weighted avg    0.59834   0.59280   0.58738     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predtest_ = logisticCV_classifier.predict(xtest_)\n",
    "\n",
    "report = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for SVM classifier model is 0.59404.\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Support Vector Machines\n",
    "name = 'SVM classifier'\n",
    "\n",
    "SVM_classifier = LinearSVC().fit(xtrain_, ytrain_)\n",
    "score = SVM_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (SVM_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} model is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\.conda\\envs\\ada\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Neural Network classifier is 0.61628.\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#### BASELINE : Neural Networks\n",
    "\n",
    "# Neural Network\n",
    "name = 'Neural Network'\n",
    "\n",
    "nn_classifier = MLPClassifier().fit(xtrain_,ytrain_)\n",
    "score = nn_classifier.score(xtest_,ytest_)\n",
    "\n",
    "classifiers[name] = (nn_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} classifier is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos    0.63495   0.54231   0.58499     12467\n",
      "         neg    0.60242   0.68986   0.64318     12533\n",
      "\n",
      "    accuracy                        0.61628     25000\n",
      "   macro avg    0.61869   0.61609   0.61409     25000\n",
      "weighted avg    0.61865   0.61628   0.61416     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predtest_ = nn_classifier.predict(xtest_)\n",
    "\n",
    "metrics = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5, output_dict=True)\n",
    "report = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save baseline results\n",
    "path = '../results/'\n",
    "name = path+'metrics_'+str(local_t_size)+'_'+str(embeddings_dim_info)+'_baseline'\n",
    "np.save(name, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing\n",
    "This section is dedicated to using the previous classifiers to predict the labels of the provided testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To format the testing data\n",
    "def extract_tweet(tweet):\n",
    "    return tweet.split(\",\", 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>had a nice time w / my friend lastnite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>&lt;user&gt; no it's not ! please stop !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>not without my daughter ( dvd two-time oscar (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>&lt;user&gt; have fun in class sweetcheeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>making a r . e . a . l . difference . ( get r ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet\n",
       "1      sea doo pro sea scooter ( sports with the port...\n",
       "2      <user> shucks well i work all week so now i ca...\n",
       "3                i cant stay away from bug thats my baby\n",
       "4      <user> no ma'am ! ! ! lol im perfectly fine an...\n",
       "5      whenever i fall asleep watching the tv , i alw...\n",
       "...                                                  ...\n",
       "9996              had a nice time w / my friend lastnite\n",
       "9997                  <user> no it's not ! please stop !\n",
       "9998   not without my daughter ( dvd two-time oscar (...\n",
       "9999                <user> have fun in class sweetcheeks\n",
       "10000  making a r . e . a . l . difference . ( get r ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading data\n",
    "\n",
    "# Load the testing data\n",
    "test = pd.read_fwf(data_path+ 'test_data.txt', sep=\"\\n\", header=None)\n",
    "test = test.rename(columns={0:'tweet', 1:'na1', 2:'na2'})\n",
    "\n",
    "# Reformating it for submission\n",
    "test.index = test.index+1 # Format asked by AI Crowd\n",
    "test = test['tweet'].map(extract_tweet).to_frame()\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.14106374638176422,\n",
       "  -0.06872910829415042,\n",
       "  0.10606407952823267,\n",
       "  -0.09969504582330192,\n",
       "  -0.09938122724092968,\n",
       "  0.28317441988314734,\n",
       "  0.12138428352938964,\n",
       "  -0.1517520964155663,\n",
       "  0.10356461464215022,\n",
       "  -0.11447167273952473,\n",
       "  -0.1019050178288262,\n",
       "  0.04473441812472089,\n",
       "  0.12753700910123314,\n",
       "  -0.014779420598848767,\n",
       "  0.10883114641696463,\n",
       "  -0.027001854853501504,\n",
       "  0.10577392355516102,\n",
       "  -0.01237564492214693,\n",
       "  -0.08728130073213365,\n",
       "  -1.3278300604051836e-05,\n",
       "  0.001988548783500319,\n",
       "  0.09713995903112027,\n",
       "  0.15960496406624083,\n",
       "  0.03955682032454823,\n",
       "  0.06123988498368808,\n",
       "  0.017050798883699113,\n",
       "  0.021711058586347004,\n",
       "  0.02652509905392398,\n",
       "  0.07778597342590884,\n",
       "  0.04948356934673396,\n",
       "  -0.0368192989347208,\n",
       "  0.0066128325730812725,\n",
       "  -0.05402086630132191,\n",
       "  0.06544012906493839,\n",
       "  0.00942711268585168,\n",
       "  -0.14003847327412292,\n",
       "  0.027678123328473192,\n",
       "  -0.024907247810668574,\n",
       "  0.06029466012331888,\n",
       "  -0.016807239895609543,\n",
       "  -0.0875419342687434,\n",
       "  -0.04261577293113893,\n",
       "  0.11665006511772064,\n",
       "  0.10424347789356216,\n",
       "  0.09065668476775407,\n",
       "  -0.0712477460271564,\n",
       "  0.010048375374466706,\n",
       "  -0.035087724165988966,\n",
       "  -0.26974756602822175,\n",
       "  0.06364401282229601,\n",
       "  -0.0440539067606717,\n",
       "  0.032875744690894444,\n",
       "  -0.12675307621723958,\n",
       "  0.05949009368330627,\n",
       "  -0.035142339244565016,\n",
       "  -0.06629684179788417,\n",
       "  0.10547315866192342,\n",
       "  -0.09329974374435464,\n",
       "  -0.01413198842247681,\n",
       "  0.012264866018115559,\n",
       "  0.052136244650516694,\n",
       "  -0.12438108362305518,\n",
       "  0.09422845669063583,\n",
       "  0.024318834761198702,\n",
       "  -0.18860665956392872,\n",
       "  -0.028167241874781743,\n",
       "  -0.06055845386204567,\n",
       "  -0.012542797652843591,\n",
       "  0.04552125605660517,\n",
       "  -0.12273535036829943,\n",
       "  0.12492030875498858,\n",
       "  0.028351983965074982,\n",
       "  -0.11952271492079339,\n",
       "  -0.057786588021433924,\n",
       "  0.01842137043937127,\n",
       "  0.07758446316468161,\n",
       "  0.17778459464394572,\n",
       "  -0.08445734149200396,\n",
       "  -0.07665869782376389,\n",
       "  -0.061262283591699815,\n",
       "  0.10821497359691001,\n",
       "  -0.06079697069079727,\n",
       "  -0.029839746094171577,\n",
       "  0.11188236825010185,\n",
       "  -0.014025794936675703,\n",
       "  0.037293296018738355,\n",
       "  0.03914765625821272,\n",
       "  -0.05283471247849066,\n",
       "  -0.10290415313711848,\n",
       "  -0.06730850085206634,\n",
       "  -0.027857464350132557,\n",
       "  0.03973135534008262,\n",
       "  -0.020311469840145695,\n",
       "  -0.010761686714304334,\n",
       "  0.0005682237091903844,\n",
       "  0.18333041263830585,\n",
       "  0.05020543802966988,\n",
       "  0.014641119198898793,\n",
       "  -0.03685163802530108,\n",
       "  -0.026434765557483978,\n",
       "  0.03262837036513885,\n",
       "  -0.06272270618074816,\n",
       "  -0.03044923595868802,\n",
       "  -0.03855249731768479,\n",
       "  0.08164073704134985,\n",
       "  -0.1211015880589725,\n",
       "  0.13156307126422065,\n",
       "  0.009166898173689245,\n",
       "  0.06275334381075298,\n",
       "  -0.05704811132077338,\n",
       "  0.09680177347833328,\n",
       "  0.14154389552867944,\n",
       "  -0.05001758962771766,\n",
       "  -0.20960397895325725,\n",
       "  -0.13551735469666376,\n",
       "  -0.1280145419684481,\n",
       "  0.11860323505658679,\n",
       "  -0.049118733797084646,\n",
       "  0.13515158421349632,\n",
       "  0.07862071972877396,\n",
       "  -0.18663725717170848,\n",
       "  0.00882031419443424,\n",
       "  0.03322616529629942,\n",
       "  -0.09956245225996994,\n",
       "  0.02232274004274916,\n",
       "  -0.07986310767739116,\n",
       "  0.08770652491895717,\n",
       "  0.05949570171665659,\n",
       "  -0.10071625706500445,\n",
       "  0.11503377536927364,\n",
       "  0.13539128876038262,\n",
       "  0.07623197845334144,\n",
       "  0.009964564616568593,\n",
       "  -0.06909490739713033,\n",
       "  -0.10260165575863398,\n",
       "  0.030072505680997518,\n",
       "  -0.012282756390174576,\n",
       "  0.005910365460746741,\n",
       "  0.048478421887372426,\n",
       "  0.02820791825244586,\n",
       "  -0.13517636602153427,\n",
       "  -0.006632401079868198,\n",
       "  -0.027255415619576732,\n",
       "  -0.05772995973028955,\n",
       "  0.11863800548045338,\n",
       "  0.03402915829294161,\n",
       "  0.02235535436053372,\n",
       "  0.03567663902849404,\n",
       "  -0.019602554762065155,\n",
       "  0.102855203353515,\n",
       "  -0.20151590466411082,\n",
       "  0.039934477393958535,\n",
       "  0.09400363669062899,\n",
       "  0.11469328949504339,\n",
       "  -0.10652527503191832,\n",
       "  0.07441283665010923,\n",
       "  -0.0329971296479177,\n",
       "  -0.09092755765576055,\n",
       "  -0.02374389954259662,\n",
       "  -0.028033841300560653,\n",
       "  -0.02323900349383668,\n",
       "  0.06897644462050868,\n",
       "  0.06365356577278637,\n",
       "  -0.06818480290009962,\n",
       "  -0.09145223479357477,\n",
       "  0.11278342297109385,\n",
       "  -0.006432212754566915,\n",
       "  0.04429745271808121,\n",
       "  -0.013898266122671072,\n",
       "  0.13839248584195357,\n",
       "  0.062103698048428954,\n",
       "  -0.03378862915727817,\n",
       "  0.041800832680191864,\n",
       "  0.09719491731424143,\n",
       "  -0.0029781015811702893,\n",
       "  0.0838550514792844,\n",
       "  0.041908316279916945,\n",
       "  -0.033279983544996714,\n",
       "  -0.06202626148353708,\n",
       "  0.05118042080266603,\n",
       "  0.052605818576992064,\n",
       "  -0.08264539342326903,\n",
       "  -0.06371188153576923,\n",
       "  0.004337611873692238,\n",
       "  0.04631411027756831,\n",
       "  -0.026653359256415016,\n",
       "  0.03675092756708122,\n",
       "  -0.030983849491570632,\n",
       "  -0.0713243375863476,\n",
       "  0.0013428733964195702,\n",
       "  -0.10166178563154664,\n",
       "  -0.03984788855712338,\n",
       "  -0.08668377367130484,\n",
       "  0.05603103883740931,\n",
       "  -0.01748534998520071,\n",
       "  0.04506258736544387,\n",
       "  0.01606411814596408,\n",
       "  -0.024207999172988753,\n",
       "  -0.012812190618577237,\n",
       "  -0.062005930331201844,\n",
       "  -0.1059110148578383,\n",
       "  -0.030942684294537486,\n",
       "  0.14066771385273177,\n",
       "  0.05996050121820201,\n",
       "  -0.08469827654813718,\n",
       "  0.12240996097044496,\n",
       "  -0.12423736194648838,\n",
       "  -0.016051378003414454,\n",
       "  0.06487560295729052,\n",
       "  0.09338520304328218,\n",
       "  0.10972281804440209,\n",
       "  -0.07111111432075339,\n",
       "  -0.07611746440038625,\n",
       "  -0.04496160947954023,\n",
       "  -0.0735330885508743,\n",
       "  0.01828275854306231,\n",
       "  -0.048148769770832794,\n",
       "  0.09563634898291114,\n",
       "  -0.03974691570173653,\n",
       "  0.06496111699675693,\n",
       "  -0.06596569035018383,\n",
       "  -0.06871499478561352,\n",
       "  -0.012270806508169304,\n",
       "  0.16607377340087423,\n",
       "  -0.02432451220828366,\n",
       "  -0.05947393413328881,\n",
       "  0.027453517217369876,\n",
       "  -0.11782193882904281,\n",
       "  0.07968027845800105,\n",
       "  -0.12020980002101635,\n",
       "  0.01281105415904757,\n",
       "  0.05103682140598822,\n",
       "  0.039330224021662745,\n",
       "  -0.06670296405734308,\n",
       "  0.11050840257335905,\n",
       "  0.07495102125915233,\n",
       "  -0.007695167097480572,\n",
       "  -0.10118653992384351,\n",
       "  -0.0329868375125386,\n",
       "  -0.053944579118865174,\n",
       "  0.02117099010507754,\n",
       "  0.06105229251882666,\n",
       "  -0.030282752155005525,\n",
       "  0.2022854189611981,\n",
       "  0.1382314761997213,\n",
       "  -0.11377243462421939,\n",
       "  0.002568651314806142,\n",
       "  -0.0009077034517041808,\n",
       "  0.04182439159609849,\n",
       "  0.05945254301407715]]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preparing data\n",
    "\n",
    "# Create word vectors for tweets\n",
    "test['mean_embed'] = test['tweet'].map(word_vector)\n",
    "\n",
    "# Preprocess test data\n",
    "xtest = preprocess(test.mean_embed.copy().tolist())\n",
    "\n",
    "xtest[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models computed so far are the following.\n",
      " \n",
      "Classifier                                         | R2 Score            \n",
      "-----------------------------------------------------------------\n",
      "Linear Model                                       | 0.0528607913\n",
      "Logistic Regression                                | 0.5927200000\n",
      "Logistic Regression using cross-validation         | 0.5928000000\n",
      "SVM classifier                                     | 0.5940400000\n",
      "Neural Network                                     | 0.6162800000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalling classifiers \n",
    "# stored in format : 'classifier name'=(classifier, R2 score) \n",
    "\n",
    "print(f\"Models computed so far are the following.\\n \")\n",
    "print(f\"{'Classifier':50s} | {'R2 Score':20s}\")\n",
    "print(f\"-----------------------------------------------------------------\")\n",
    "for k,v in classifiers.items() :\n",
    "    print(f\"{k:50s} | {v[1]:10.10f}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "model = classifiers['Neural Network'][0]\n",
    "\n",
    "predictions = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating submission file\n",
    "import csv\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})\n",
    "            \n",
    "create_csv_submission(test.index, predictions, '../submission/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Here we detail previously computed results from `results/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Dimensions evolution\n",
    "Below we detail how different metrics perform when the dimension of the word embeddings computed by GloVe algorithm changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 dimensions\n",
      "\n",
      "Accuracy : 0.585\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.574874 |   0.671121 |   0.619280\n",
      "neg        |   0.599399 |   0.497868 |   0.543936\n",
      "\n",
      "50 dimensions\n",
      "\n",
      "Accuracy : 0.5896\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.575301 |   0.671701 |   0.619775\n",
      "neg        |   0.609460 |   0.508167 |   0.554223\n",
      "\n",
      "100 dimensions\n",
      "\n",
      "Accuracy : 0.60904\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.587911 |   0.726698 |   0.649979\n",
      "neg        |   0.643141 |   0.491608 |   0.557257\n",
      "\n",
      "250 dimensions\n",
      "\n",
      "Accuracy : 0.61628\n",
      "Label      | precision  | recall     | f1-score  \n",
      "pos        |   0.634955 |   0.542312 |   0.584988\n",
      "neg        |   0.602425 |   0.689859 |   0.643184\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "precs = []\n",
    "recs = []\n",
    "f1s = []\n",
    "\n",
    "\n",
    "for d in [20,50,100,250] :\n",
    "    print(f'\\n{d} dimensions\\n')\n",
    "    name = path+'metrics_'+str(local_t_size)+'_'+str(d)+'_baseline.npy'\n",
    "    r = np.load(name, allow_pickle=True)\n",
    "    r = r.item()\n",
    "    print(f\"Accuracy : {r['accuracy']}\")\n",
    "    print(f\"{'Label':10s} | {'precision':10s} | {'recall':10s} | {'f1-score':10s}\")\n",
    "    print(f\"{'pos':10s} | {r['pos']['precision']:10f} | {r['pos']['recall']:10f} | {r['pos']['f1-score']:10f}\")    \n",
    "    print(f\"{'neg':10s} | {r['neg']['precision']:10f} | {r['neg']['recall']:10f} | {r['neg']['f1-score']:10f}\")  \n",
    "    accs.append(r['accuracy'])\n",
    "    precs.append(r['pos']['precision'])\n",
    "    recs.append(r['pos']['recall'])\n",
    "    f1s.append(r['pos']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [20,50,100,250]\n",
    "plt.plot(x, accs)\n",
    "plt.plot(x, precs)\n",
    "plt.plot(x, recs)\n",
    "plt.plot(x, f1s)\n",
    "plt.legend(['accuracy','precision','recall','f1-score'])\n",
    "plt.xticks(ticks=np.arange(0,260,20))\n",
    "plt.vlines(190,ymin=0.53, ymax=0.725, color='black')\n",
    "name = '../plots/'+'metrics_'+str(local_t_size)+'_dims_baseline.png'\n",
    "plt.savefig(name, dpi=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the optimal number of dimensions seems to lie around **190** as the parameters are at their common highest at this point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
