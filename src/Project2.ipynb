{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Loading\n",
    "\n",
    "In this section we load the data for :\n",
    "* positive tweets, label= `:)` ($1$ for classification) \n",
    "* negative tweets, label= `:(` ($-1$ for classification)\n",
    "\n",
    "Full data is used below (1'250'000 tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded POS data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : True\n",
      "Number of tweets : (POS) 1250000 (NEG) 1250000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because your logic is so dumb , i won't even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" &lt;user&gt; just put casper in a box ! \" looved t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; thanks sir &gt; &gt; don't trip lil ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting my brother tmr is the bestest birthda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249995</th>\n",
       "      <td>im so sorry ! &lt;user&gt; &amp; to &lt;user&gt; &amp; &lt;user&gt; u gu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249996</th>\n",
       "      <td>i can't find food coloring anywhere</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249997</th>\n",
       "      <td>&lt;user&gt; same here ! ! but tort ! ! wonder why y...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249998</th>\n",
       "      <td>keyless entry remote fob clicker for 2005 buic...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249999</th>\n",
       "      <td>&lt;user&gt; yeap . doctor don't know what's wrong w...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "0        <user> i dunno justin read my mention or not ....      1\n",
       "1        because your logic is so dumb , i won't even c...      1\n",
       "2        \" <user> just put casper in a box ! \" looved t...      1\n",
       "3        <user> <user> thanks sir > > don't trip lil ma...      1\n",
       "4        visiting my brother tmr is the bestest birthda...      1\n",
       "...                                                    ...    ...\n",
       "1249995  im so sorry ! <user> & to <user> & <user> u gu...     -1\n",
       "1249996                i can't find food coloring anywhere     -1\n",
       "1249997  <user> same here ! ! but tort ! ! wonder why y...     -1\n",
       "1249998  keyless entry remote fob clicker for 2005 buic...     -1\n",
       "1249999  <user> yeap . doctor don't know what's wrong w...     -1\n",
       "\n",
       "[2500000 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "\n",
    "## Load full training sets\n",
    "# positive\n",
    "pos = pd.read_table(data_path+'train_pos_full.txt', sep='.\\n', names=['tweet'], engine='python')\n",
    "pos['label']=1\n",
    "print(f\"Loaded POS data, correctly interpreted 1-tweet-per-line fashion : {pos.shape[0]==1_250_000}\")\n",
    "\n",
    "# negative\n",
    "neg = pd.read_table(data_path+'train_neg_full.txt', sep='.\\n', names=['tweet'], engine='python')\n",
    "neg['label']=-1\n",
    "print(f\"Loaded NEG data, correctly interpreted 1-tweet-per-line fashion : {neg.shape[0]==1_250_000}\")\n",
    "\n",
    "# Data sizes\n",
    "print(f\"Number of tweets : (POS) {pos.shape[0]} (NEG) {neg.shape[0]}\\n\")\n",
    "\n",
    "# Merge datasets to get a complete training set\n",
    "tweets = pos.append(neg)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word embeddings in structure of type <class 'numpy.ndarray'>.\n",
      "Loaded word embeddings in structure of type <class 'pandas.core.series.Series'>.\n",
      "\n",
      "Both the embeddings and the vocabulary are same length :  True\n",
      "Embeddings: (101298, 20), vocab: (101298,)\n",
      "NA values were dropped in both tables: True\n",
      "Embeddings: (101296, 20), vocab: (101296,)\n"
     ]
    }
   ],
   "source": [
    "## Load word embeddings and vocabulary to compute word vectors of tweets\n",
    "\n",
    "# Load word embeddings\n",
    "embeddings = np.load(data_path + 'embeddings_full.npy')\n",
    "print(f'Loaded word embeddings in structure of type {type(embeddings)}.')\n",
    "\n",
    "# Loading vocab\n",
    "words = pd.read_table(data_path + 'vocab_cut.txt', sep='.\\n', names=['word'], engine='python', squeeze=True, na_values=np.nan)\n",
    "print(f'Loaded word embeddings in structure of type {type(words)}.')\n",
    "\n",
    "# Check that the vocabulary encompasses all embedded words\n",
    "print(f'\\nBoth the embeddings and the vocabulary are same length :  {len(embeddings)==words.shape[0]}')\n",
    "print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")\n",
    "\n",
    "## Clean the data\n",
    "\n",
    "# Drop NaN values in words\n",
    "nas = words.isna()\n",
    "words.dropna(inplace=True)\n",
    "embeddings = np.delete(embeddings, nas[nas].index.values, axis=0)\n",
    "print(f'NA values were dropped in both tables: {len(embeddings)==words.shape[0]}')\n",
    "print(f\"Embeddings: {embeddings.shape}, vocab: {words.shape}\")\n",
    "\n",
    "# Index by words for faster index-for-word search\n",
    "words = pd.DataFrame(data=words.index, index=words.values)\n",
    "embeddings = pd.DataFrame(embeddings, index=words.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>-0.002815</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>-0.044277</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>0.031187</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>-0.002514</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.016734</td>\n",
       "      <td>-0.008299</td>\n",
       "      <td>-0.008789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.019161</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>0.033832</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>-0.027132</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.033120</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.015588</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>0.035705</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>-0.011820</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.005041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>-0.002602</td>\n",
       "      <td>-0.022695</td>\n",
       "      <td>-0.004233</td>\n",
       "      <td>-0.033344</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>-0.023608</td>\n",
       "      <td>-0.014181</td>\n",
       "      <td>-0.004194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>-0.005454</td>\n",
       "      <td>-0.016949</td>\n",
       "      <td>-0.001816</td>\n",
       "      <td>-0.008950</td>\n",
       "      <td>-0.037330</td>\n",
       "      <td>-0.029912</td>\n",
       "      <td>-0.008472</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>-0.016195</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.010477</td>\n",
       "      <td>-0.022874</td>\n",
       "      <td>-0.001610</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.008685</td>\n",
       "      <td>-0.011349</td>\n",
       "      <td>0.006130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.002507</td>\n",
       "      <td>0.011608</td>\n",
       "      <td>0.027699</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>-0.020171</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>-0.012358</td>\n",
       "      <td>-0.045863</td>\n",
       "      <td>-0.002258</td>\n",
       "      <td>0.031533</td>\n",
       "      <td>-0.014051</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>-0.006924</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>-0.021841</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>-0.022420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "<user>  0.000327  0.028452  0.016525  0.000613  0.005188 -0.002815  0.009533   \n",
       "!      -0.019161  0.027524  0.033832  0.012091 -0.027132 -0.012628 -0.000841   \n",
       "i       0.019321  0.030986  0.014057  0.007218 -0.002602 -0.022695 -0.004233   \n",
       "the     0.002400  0.021290  0.007768 -0.005454 -0.016949 -0.001816 -0.008950   \n",
       ".      -0.002507  0.011608  0.027699  0.013425 -0.020171  0.008285 -0.012358   \n",
       "\n",
       "              7         8         9         10        11        12        13  \\\n",
       "<user> -0.044277  0.009413  0.031187  0.010009 -0.002514  0.007920  0.036842   \n",
       "!      -0.033120  0.013693 -0.004513  0.016704  0.015588 -0.008836  0.035705   \n",
       "i      -0.033344 -0.001470  0.013007  0.002135 -0.007511  0.003676  0.010762   \n",
       "the    -0.037330 -0.029912 -0.008472  0.005187 -0.016195  0.006317 -0.010477   \n",
       ".      -0.045863 -0.002258  0.031533 -0.014051  0.008234  0.008522  0.012892   \n",
       "\n",
       "              14        15        16        17        18        19  \n",
       "<user> -0.012512  0.022829 -0.000567 -0.016734 -0.008299 -0.008789  \n",
       "!       0.007875  0.015618  0.009505 -0.011820 -0.003584 -0.005041  \n",
       "i      -0.002978 -0.001809  0.010544 -0.023608 -0.014181 -0.004194  \n",
       "the    -0.022874 -0.001610 -0.006108 -0.008685 -0.011349  0.006130  \n",
       ".       0.017243 -0.006924  0.004531 -0.021841 -0.005605 -0.022420  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "<user>  0\n",
       "!       1\n",
       "i       2\n",
       "the     3\n",
       ".       4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploratory Data Analysis\n",
    "In this part we analyse our data in order to optimize its information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning tags \n",
    "Here we explore the non-spoken tags present in the tweets and determine if they are relevant for our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|KEY           |POS   |NEG   |\n",
      "|</b>          |     1|    19|\n",
      "|</span>       |     0|     1|\n",
      "|</script>     |     0|     4|\n",
      "|<thing>       |     0|     1|\n",
      "|<screams>     |     0|     1|\n",
      "|<sarah>       |     1|     0|\n",
      "|<weirdarms>   |     1|     0|\n",
      "|<sciencestuff>|     2|     0|\n",
      "|<demon>       |     0|     1|\n",
      "|</div>        |     0|     1|\n",
      "|<br>          |     1|     6|\n",
      "|<agent>       |     0|     3|\n",
      "|<c>           |     1|     2|\n",
      "|<strong>      |     0|     6|\n",
      "|<content>     |     0|     1|\n",
      "|<mournfully>  |     0|     1|\n",
      "|<del>         |     0|     1|\n",
      "|<g>           |     1|     0|\n",
      "|<joke>        |     1|     0|\n",
      "|<likewise>    |     1|     0|\n",
      "|<brr>         |     1|     0|\n",
      "|<ummm>        |     0|     1|\n",
      "|<parenthood>  |     0|     1|\n",
      "|</details>    |     1|     0|\n",
      "|</em>         |     0|     2|\n",
      "|</cfoutput>   |     0|     1|\n",
      "|<please>      |     0|     1|\n",
      "|<hugs>        |     1|     1|\n",
      "|<emotional>   |     0|     1|\n",
      "|<trans>       |     0|     3|\n",
      "|<gardenstuff> |     2|     0|\n",
      "|<w>           |     0|     1|\n",
      "|<o>           |     0|     1|\n",
      "|<calc>        |     1|     0|\n",
      "|</body>       |     0|     1|\n",
      "|<understood>  |     1|     0|\n",
      "|<hahahahhahaha>|     0|     1|\n",
      "|<ages>        |     0|     1|\n",
      "|<name>        |     0|     1|\n",
      "|</summary>    |     1|     0|\n",
      "|<haha>        |     0|     1|\n",
      "|<syrian>      |     0|     6|\n",
      "|<b>           |     1|    26|\n",
      "|<outstanding> |     1|     0|\n",
      "|<justkiddin>  |     0|     1|\n",
      "|<ducking>     |     1|     0|\n",
      "|</moan>       |     0|     1|\n",
      "|<attention>   |     0|     2|\n",
      "|<popcorn>     |     1|     0|\n",
      "|<url>         | 98886|427976|\n",
      "|</joke>       |     1|     0|\n",
      "|<update>      |     0|     2|\n",
      "|<dynamic>     |     1|     0|\n",
      "|<p>           |     0|    16|\n",
      "|<cfoutput>    |     0|     1|\n",
      "|<ht>          |     0|     1|\n",
      "|<blushing>    |     1|     0|\n",
      "|<impressive>  |     1|     0|\n",
      "|<here>        |     1|     0|\n",
      "|<user>        |1027205|578390|\n",
      "|<sigh>        |     0|     3|\n",
      "|<cutestuff>   |     2|     0|\n",
      "|<thx>         |     1|     0|\n",
      "|<blink>       |     0|     1|\n",
      "|</i>          |     0|    11|\n",
      "|<iostream>    |     0|     1|\n",
      "|<atomic>      |     0|     1|\n",
      "|<weeping>     |     0|     1|\n",
      "|<space>       |     3|     0|\n",
      "|<laugh>       |     1|     0|\n",
      "|<summary>     |     1|     0|\n",
      "|</strong>     |     0|     6|\n",
      "|</del>        |     0|     1|\n",
      "|<i>           |     0|    10|\n",
      "|<retweet>     |     0|     1|\n",
      "|</html>       |     0|     1|\n",
      "|<naive>       |     0|     1|\n",
      "|<waves>       |     1|     0|\n",
      "|<time>        |     1|     0|\n",
      "|<hot>         |     1|     0|\n",
      "|<em>          |     0|     2|\n",
      "|<script>      |     0|     2|\n",
      "|<twinkle>     |     0|     1|\n",
      "|<cont>        |     1|     0|\n",
      "|<moan>        |     0|     1|\n",
      "|</popcorn>    |     1|     0|\n",
      "|<ducks>       |     1|     0|\n",
      "|<grunt>       |     1|     0|\n",
      "|<mikel>       |     1|     0|\n",
      "|<grin>        |     2|     0|\n",
      "|</a>          |     1|     7|\n",
      "\n",
      "POS tweets contain 1126137 (11.88%) HTML tags.\n",
      "NEG tweets contain 1006539 (-10.62%) HTML tags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "## We check if the tags are relevant information between both pos and neg cases\n",
    "\n",
    "def count_HTML_tags(series) :\n",
    "    \"\"\"\n",
    "    Returns stats about the HTML tags in the tweet series.\n",
    "    Returns :\n",
    "    dic (defaultdict) : dict of all tags occurences.\n",
    "    count (int) : count of all tags.\"\"\"\n",
    "    dic = defaultdict(lambda:0)\n",
    "    def a(k):\n",
    "        dic[k]+=1\n",
    "        return None\n",
    "    series.apply(lambda s : [a(k) for k in re.findall('<\\/*[a-zA-Z]+>', s)])\n",
    "    count = series.str.count('<\\/*[a-zA-Z]+>').sum()\n",
    "    return dic, count\n",
    "\n",
    "# We query stats about the tags\n",
    "d_pos, n_pos = count_HTML_tags(pos['tweet'])\n",
    "d_neg, n_neg = count_HTML_tags(neg['tweet'])\n",
    "all_keys = set(d_pos.keys()) | set(d_neg.keys())\n",
    "\n",
    "print(f\"|{'KEY':14s}|{'POS':6s}|{'NEG':6s}|\")\n",
    "for k in all_keys : \n",
    "    print(f\"|{k:14s}|{d_pos[k]:6d}|{d_neg[k]:6d}|\")\n",
    "\n",
    "print(f\"\\nPOS tweets contain {n_pos} ({(n_pos-n_neg)*100/n_neg:.2f}%) HTML tags.\")\n",
    "print(f\"NEG tweets contain {n_neg} ({(n_neg-n_pos)*100/n_pos:.2f}%) HTML tags.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Although the difference in number of tags is not significant. The distribution of them is quite significant (i.e. for tags `<url>` and `<user>`). Thus we choose to leave the tags as part of the tweet. **THIS COULD BE REVIEWED TO IMPROVE PERF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the HTML tags from the tweets\n",
    "## CHANGE RETURN VAR IF RELEVANT\n",
    "\n",
    "def clean_HTML_tags(series) :\n",
    "    return series.str.replace('<\\/*[a-zA-Z]+>', '', regex=True)\n",
    "\n",
    "t = clean_HTML_tags(pos['tweet'])\n",
    "t2 = clean_HTML_tags(neg['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "In this part we train the models on our data.\n",
    "Thus, we perform\n",
    "* a resampling of our data to work locally on a smaller set.\n",
    "* the creation of word vectors for our tweets.\n",
    "* a train-test-split to locally estimate the model's performance.\n",
    "* cross-validation trainin on a series of models :\n",
    "    * Linear Regression\n",
    "    * Logistic Regression\n",
    "    * SVM\n",
    "    * Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base parameters\n",
    "\n",
    "# To compute size of local training set\n",
    "local_t_size = 100_000\n",
    "# location of precomputed files\n",
    "word_vectors_file_location = '../precomputed_data/'\n",
    "# indication on the number of dimensions of the embeddings that is being used\n",
    "embeddings_dim_info = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the Training set\n",
    "Using only a set of 200'000 tweets locally to decrease computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757921</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; as you can see carol they...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196488</th>\n",
       "      <td>college park with &lt;user&gt; and &lt;user&gt; ayyy .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611562</th>\n",
       "      <td>&lt;user&gt; lol ! i told you i would look back and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352088</th>\n",
       "      <td>&lt;user&gt; well thanks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361024</th>\n",
       "      <td>&lt;user&gt; ha ha i like his tattoo's thats about i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841954</th>\n",
       "      <td>trend spotting : pop star rita ora rocks monok...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995160</th>\n",
       "      <td>i do not want to do this history essay such a ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241855</th>\n",
       "      <td>don't want to work</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215945</th>\n",
       "      <td>&lt;user&gt; yeah she did and im doing that with you...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882585</th>\n",
       "      <td>aw , i miss london want to go back so much</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "757921   <user> <user> <user> as you can see carol they...      1\n",
       "1196488         college park with <user> and <user> ayyy .      1\n",
       "611562   <user> lol ! i told you i would look back and ...      1\n",
       "352088                                  <user> well thanks      1\n",
       "361024   <user> ha ha i like his tattoo's thats about i...      1\n",
       "...                                                    ...    ...\n",
       "841954   trend spotting : pop star rita ora rocks monok...     -1\n",
       "995160   i do not want to do this history essay such a ...     -1\n",
       "241855                                  don't want to work     -1\n",
       "1215945  <user> yeah she did and im doing that with you...     -1\n",
       "882585          aw , i miss london want to go back so much     -1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Take only `0.5*local_t_size` samples from both classes for faster computation\n",
    "n = int(local_t_size/2)\n",
    "pos_ = resample(pos, n_samples=n, replace=False)\n",
    "neg_ = resample(neg, n_samples=n, replace=False)\n",
    "tweets_ = pos_.append(neg_)\n",
    "\n",
    "tweets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for 101,296.0 with 20 features for each word.\n",
      "Embeddings shape : (101296, 20).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>-0.002815</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>-0.044277</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>0.031187</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>-0.002514</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.016734</td>\n",
       "      <td>-0.008299</td>\n",
       "      <td>-0.008789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.019161</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>0.033832</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>-0.027132</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.033120</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.015588</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>0.035705</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>-0.011820</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.005041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "<user>  0.000327  0.028452  0.016525  0.000613  0.005188 -0.002815  0.009533   \n",
       "!      -0.019161  0.027524  0.033832  0.012091 -0.027132 -0.012628 -0.000841   \n",
       "\n",
       "              7         8         9         10        11        12        13  \\\n",
       "<user> -0.044277  0.009413  0.031187  0.010009 -0.002514  0.007920  0.036842   \n",
       "!      -0.033120  0.013693 -0.004513  0.016704  0.015588 -0.008836  0.035705   \n",
       "\n",
       "              14        15        16        17        18        19  \n",
       "<user> -0.012512  0.022829 -0.000567 -0.016734 -0.008299 -0.008789  \n",
       "!       0.007875  0.015618  0.009505 -0.011820 -0.003584 -0.005041  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall our data\n",
    "print(f\"Embeddings for {embeddings.shape[0]:,.1f} with {embeddings.shape[1]} features for each word.\") \n",
    "print(f'Embeddings shape : {embeddings.shape}.\\n')\n",
    "embeddings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tweet):\n",
    "    \"\"\"\n",
    "    Creates the feature vector corresponding to the tweet.\n",
    "    To do so, computes the mean of the word embeddings corresponding to the vocabulary words in the tweet.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    tweet : str\n",
    "        Input tweet from which the word vector is created.\n",
    "    \"\"\"\n",
    "    split_by_words = tweet.split()\n",
    "    embed_list = []\n",
    "    \n",
    "    # Get vocab word embeddings\n",
    "    for w in split_by_words:\n",
    "        if w in words.index :\n",
    "            embed_list.append(  embeddings.loc[w].values  )\n",
    "        \n",
    "    # Compute mean if any vocab word was found\n",
    "    mean = np.zeros(20) if not embed_list else np.mean(embed_list, axis=0) \n",
    "    return mean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load word vectors from ../precomputed_data/word_vectors_100000_20.npy\n",
      "Successfully loaded from file!\n",
      "Wall time: 696 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pandas.errors import MergeError\n",
    "\n",
    "try :\n",
    "    # Load pre-computed word vectors file if possible \n",
    "    name = word_vectors_file_location+'word_vectors_'+str(local_t_size)+'_'+str(embeddings_dim_info)+'.npy'\n",
    "    print(f\"Trying to load word vectors from {name}\")\n",
    "    precomputed = np.load(name, allow_pickle=True)\n",
    "    \n",
    "    # Transform into Dataframe for merge\n",
    "    precomputed = pd.DataFrame(precomputed, columns=['index', 'label', 'mean_embed'])\n",
    "    pos_ = pos.loc[precomputed.loc[precomputed['label']==1, 'index']]\n",
    "    neg_ = neg.loc[precomputed.loc[precomputed['label']==-1, 'index']]\n",
    "    tweets_ = pos_.append(neg_).reset_index()\n",
    "    tweets_ = tweets_.merge(precomputed, how='inner', on=['index', 'label'], validate='1:1').set_index('index')\n",
    "    print('Successfully loaded from file!')\n",
    "    \n",
    "except (FileNotFoundError) as e :\n",
    "    print('Could not load word vectors from file...\\nRecomputing word vectors...')\n",
    "    # Create word vectors for the local dataset\n",
    "    tweets_['mean_embed']= tweets_['tweet'].map(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_embed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1020761</th>\n",
       "      <td>&lt;user&gt; kus niggas tryna find new ways to get f...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.006111815659464072, 0.7197322757532972, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690958</th>\n",
       "      <td>joanna symons suggests how to find accommodati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.017124226010274895, 0.4027337962952229, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656365</th>\n",
       "      <td>&lt;user&gt; what time ?</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.06875733450303735, 0.5183489266332838, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384680</th>\n",
       "      <td>&lt;user&gt; it was the right tweet son</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.09417493947047391, 0.5709764570942454, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393805</th>\n",
       "      <td>i wanna go . rt &lt;user&gt; finna go go buffalo wil...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.10825893930221646, 0.5741484203775674, 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210752</th>\n",
       "      <td>novica blown wine glasses , ' crimson serpenti...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.06386397143353187, 0.5318056923844712, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97104</th>\n",
       "      <td>walthers ho scale hs #902074 ttwx all purpose ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.09309077043951619, 0.5157496136248376, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975497</th>\n",
       "      <td>&lt;--- ain't had sex in a long time . i'm gonna ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.09434767776236758, 0.6438721760825019, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947116</th>\n",
       "      <td>belle hop set of 2 leopard locks and 2 leopard...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.26867250090849304, 0.4005419460636976, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420569</th>\n",
       "      <td>degrassi junior high : spike ( paperback spike...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0.11770396074641792, 0.5151054235308394, 0.12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet label  \\\n",
       "index                                                              \n",
       "1020761  <user> kus niggas tryna find new ways to get f...     1   \n",
       "690958   joanna symons suggests how to find accommodati...     1   \n",
       "656365                                  <user> what time ?     1   \n",
       "384680                   <user> it was the right tweet son     1   \n",
       "393805   i wanna go . rt <user> finna go go buffalo wil...     1   \n",
       "...                                                    ...   ...   \n",
       "210752   novica blown wine glasses , ' crimson serpenti...    -1   \n",
       "97104    walthers ho scale hs #902074 ttwx all purpose ...    -1   \n",
       "975497   <--- ain't had sex in a long time . i'm gonna ...    -1   \n",
       "947116   belle hop set of 2 leopard locks and 2 leopard...    -1   \n",
       "420569   degrassi junior high : spike ( paperback spike...    -1   \n",
       "\n",
       "                                                mean_embed  \n",
       "index                                                       \n",
       "1020761  [0.006111815659464072, 0.7197322757532972, -0....  \n",
       "690958   [-0.017124226010274895, 0.4027337962952229, 0....  \n",
       "656365   [0.06875733450303735, 0.5183489266332838, 0.04...  \n",
       "384680   [0.09417493947047391, 0.5709764570942454, 0.04...  \n",
       "393805   [0.10825893930221646, 0.5741484203775674, 0.20...  \n",
       "...                                                    ...  \n",
       "210752   [0.06386397143353187, 0.5318056923844712, -0.0...  \n",
       "97104    [0.09309077043951619, 0.5157496136248376, 0.12...  \n",
       "975497   [0.09434767776236758, 0.6438721760825019, 0.05...  \n",
       "947116   [0.26867250090849304, 0.4005419460636976, 0.07...  \n",
       "420569   [0.11770396074641792, 0.5151054235308394, 0.12...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word vectors file to gain time\n",
    "word_vectors = tweets_[['label', 'mean_embed']].reset_index()\n",
    "name = word_vectors_file_location+'word_vectors_'+str(local_t_size)+'_'+str(embeddings_dim_info)\n",
    "\n",
    "np.save(name, word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split for our local dataset\n",
    "We divide our local training set into a 75% training set and a 25% local testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local training set size : (375000, 3).\n",
      "Local testing set size : (125000, 3).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_, test_ = train_test_split(tweets_, test_size=0.25)\n",
    "print(f\"Local training set size : {train_.shape}.\")\n",
    "print(f\"Local testing set size : {test_.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.11209293083648302,\n",
       "  0.8379536320000046,\n",
       "  0.06435265794088334,\n",
       "  0.28261244119135703,\n",
       "  -0.4116261995677197,\n",
       "  -0.0037634530456671076,\n",
       "  -0.06068811384656975,\n",
       "  -0.4951261722005948,\n",
       "  -0.1770969131120541,\n",
       "  -0.13442795039758862,\n",
       "  -0.30454069901345904,\n",
       "  0.2862791843832266,\n",
       "  -0.2972696497099928,\n",
       "  -0.010056398270032085,\n",
       "  -0.05267474284327053,\n",
       "  -0.16724661835906388,\n",
       "  -0.031884223678409644,\n",
       "  -0.11216669698455584,\n",
       "  -0.4264506111642759,\n",
       "  0.1936082316094817]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features and label datasets\n",
    "xtrain_, ytrain_ = train_.mean_embed.copy().tolist(), train_.label.copy().to_list()\n",
    "xtest_, ytest_ = test_.mean_embed.copy().tolist(), test_.label.copy().tolist()\n",
    "\n",
    "xtrain_[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing\n",
    "Here we compute our pre-processing on features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "def preprocess(X) :\n",
    "    x=X.copy()\n",
    "    \n",
    "    # Standardize data\n",
    "    standardizer=StandardScaler().fit_transform(x)\n",
    "    \n",
    "    # TODO Polynomial features and interactions\n",
    "    \n",
    "    # other data preprocessing\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process training set\n",
    "\n",
    "xtrain_ = preprocess(xtrain_)\n",
    "xtest_ = preprocess(xtest_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating efficiency of model\n",
    "Here we define metrics for model classification efficiency.\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Training\n",
    "* Linear Regression\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Linear Model is 0.013335540112904831.\n",
      "Wall time: 1.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Linear Regression\n",
    "name = 'Linear Model'\n",
    "\n",
    "linear_classifier = LinearRegression().fit(xtrain_, ytrain_)\n",
    "score = linear_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (linear_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Logistic Regression is 0.54616.\n",
      "R2 score for Logistic Regression model using cross-validation is 0.546104.\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#### BASELINE : Logistic Regression\n",
    "\n",
    "# Logistic Regression\n",
    "name = 'Logistic Regression'\n",
    "\n",
    "logistic_classifier = LogisticRegression().fit(xtrain_, ytrain_)\n",
    "score = logistic_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (logistic_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} is {score}.\")\n",
    "\n",
    "# Logistic Regression using Crossvalidation\n",
    "name = 'Logistic Regression using cross-validation'\n",
    "\n",
    "logisticCV_classifier = LogisticRegressionCV().fit(xtrain_, ytrain_)\n",
    "score = logisticCV_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (logisticCV_classifier, score)\n",
    "\n",
    "print(f\"R2 score for Logistic Regression model using cross-validation is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos    0.53708   0.64278   0.58520     62256\n",
      "         neg    0.55955   0.45029   0.49901     62744\n",
      "\n",
      "    accuracy                        0.54616    125000\n",
      "   macro avg    0.54832   0.54654   0.54210    125000\n",
      "weighted avg    0.54836   0.54616   0.54194    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predtest_ = logistic_classifier.predict(xtest_)\n",
    "\n",
    "report = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos    0.53703   0.64281   0.58518     62256\n",
      "         neg    0.55950   0.45015   0.49890     62744\n",
      "\n",
      "    accuracy                        0.54610    125000\n",
      "   macro avg    0.54826   0.54648   0.54204    125000\n",
      "weighted avg    0.54831   0.54610   0.54187    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predtest_ = logisticCV_classifier.predict(xtest_)\n",
    "\n",
    "report = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for SVM classifier model is 0.54628.\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Support Vector Machines\n",
    "name = 'SVM classifier'\n",
    "\n",
    "SVM_classifier = LinearSVC().fit(xtrain_, ytrain_)\n",
    "score = SVM_classifier.score(xtest_, ytest_)\n",
    "\n",
    "classifiers[name] = (SVM_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} model is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for Neural Network classifier is 0.582856.\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Neural Network\n",
    "name = 'Neural Network'\n",
    "\n",
    "nn_classifier = MLPClassifier().fit(xtrain_,ytrain_)\n",
    "score = nn_classifier.score(xtest_,ytest_)\n",
    "\n",
    "classifiers[name] = (nn_classifier, score)\n",
    "\n",
    "print(f\"R2 score for {name} classifier is {score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos    0.56868   0.67255   0.61627     62256\n",
      "         neg    0.60318   0.49386   0.54307     62744\n",
      "\n",
      "    accuracy                        0.58286    125000\n",
      "   macro avg    0.58593   0.58320   0.57967    125000\n",
      "weighted avg    0.58599   0.58286   0.57953    125000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "predtest_ = nn_classifier.predict(xtest_)\n",
    "\n",
    "report = classification_report(ytest_, predtest_, labels=[1,-1], target_names=['pos', 'neg'], digits=5)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing\n",
    "This section is dedicated to using the previous classifiers to predict the labels of the provided testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To format the testing data\n",
    "def extract_tweet(tweet):\n",
    "    return tweet.split(\",\", 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>had a nice time w / my friend lastnite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>&lt;user&gt; no it's not ! please stop !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>not without my daughter ( dvd two-time oscar (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>&lt;user&gt; have fun in class sweetcheeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>making a r . e . a . l . difference . ( get r ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet\n",
       "1      sea doo pro sea scooter ( sports with the port...\n",
       "2      <user> shucks well i work all week so now i ca...\n",
       "3                i cant stay away from bug thats my baby\n",
       "4      <user> no ma'am ! ! ! lol im perfectly fine an...\n",
       "5      whenever i fall asleep watching the tv , i alw...\n",
       "...                                                  ...\n",
       "9996              had a nice time w / my friend lastnite\n",
       "9997                  <user> no it's not ! please stop !\n",
       "9998   not without my daughter ( dvd two-time oscar (...\n",
       "9999                <user> have fun in class sweetcheeks\n",
       "10000  making a r . e . a . l . difference . ( get r ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading data\n",
    "\n",
    "# Load the testing data\n",
    "test = pd.read_fwf(data_path+ 'test_data.txt', sep=\"\\n\", header=None)\n",
    "test = test.rename(columns={0:'tweet', 1:'na1', 2:'na2'})\n",
    "\n",
    "# Reformating it for submission\n",
    "test.index = test.index+1 # Format asked by AI Crowd\n",
    "test = test['tweet'].map(extract_tweet).to_frame()\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.06600514685663708,\n",
       "  0.582784556899372,\n",
       "  -0.04151115815776958,\n",
       "  0.13666445264367844,\n",
       "  -0.1977931317665288,\n",
       "  -0.016802999768011986,\n",
       "  -0.038712791935644156,\n",
       "  -0.2545744725436583,\n",
       "  0.029000791532073186,\n",
       "  0.06613123578801591,\n",
       "  -0.14071631816239816,\n",
       "  0.147312012718148,\n",
       "  -0.2390666239629726,\n",
       "  0.08578977417972455,\n",
       "  -0.0034186956612259254,\n",
       "  -0.052978385981814986,\n",
       "  0.16010788866987907,\n",
       "  -0.07031762344866747,\n",
       "  -0.2815485402300905,\n",
       "  0.16404086032326892]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preparing data\n",
    "\n",
    "# Create word vectors for tweets\n",
    "test['mean_embed'] = test['tweet'].map(word_vector)\n",
    "\n",
    "# Preprocess test data\n",
    "xtest = preprocess(test.mean_embed.copy().tolist())\n",
    "\n",
    "xtest[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models computed so far are the following.\n",
      " \n",
      "Classifier                                         | R2 Score            \n",
      "-----------------------------------------------------------------\n",
      "Linear Model                                       | 0.0133355401\n",
      "Logistic Regression                                | 0.5461600000\n",
      "Logistic Regression using cross-validation         | 0.5461040000\n",
      "SVM classifier                                     | 0.5462800000\n",
      "Neural Network                                     | 0.5828560000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalling classifiers \n",
    "# stored in format : 'classifier name'=(classifier, R2 score) \n",
    "\n",
    "print(f\"Models computed so far are the following.\\n \")\n",
    "print(f\"{'Classifier':50s} | {'R2 Score':20s}\")\n",
    "print(f\"-----------------------------------------------------------------\")\n",
    "for k,v in classifiers.items() :\n",
    "    print(f\"{k:50s} | {v[1]:10.10f}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "model = classifiers['Neural Network'][0]\n",
    "\n",
    "predictions = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating submission file\n",
    "import csv\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})\n",
    "            \n",
    "create_csv_submission(test.index, predictions, '../submission/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
